[
  {
    "objectID": "LABORATORIO_2.html",
    "href": "LABORATORIO_2.html",
    "title": "Laboratorio",
    "section": "",
    "text": "# ====== Importar librerías ======\nimport re\nimport unicodedata\nimport numpy as np\nimport pandas as pd\nimport altair as alt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    classification_report, ConfusionMatrixDisplay\n)\n\n# NLTK\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nnltk.download(\"punkt\", quiet=True)\nnltk.download(\"stopwords\", quiet=True)\nstop_es = stopwords.words(\"spanish\")",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#función-de-limpieza",
    "href": "LABORATORIO_2.html#función-de-limpieza",
    "title": "Laboratorio",
    "section": "Función de limpieza",
    "text": "Función de limpieza\n\ndef normalize_text(text: str) -&gt; str:\n    text = str(text)\n    text = text.lower().strip()\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)  # URLs\n    text = re.sub(r\"@\\w+\", \" \", text)                   # menciones\n    text = re.sub(r\"#\\w+\", \" \", text)                   # hashtags (como texto)\n    text = re.sub(r\"[^a-zñ\\s]\", \" \", text)              # solo letras y espacios\n    text = re.sub(r\"\\s+\", \" \", text).strip()            # espacios extra\n    return text\n\n\ntweets[\"clean_text\"] = tweets[\"content\"].fillna(\"\").astype(str).apply(normalize_text)\n\n# Creación de algunas features simples de texto\ntweets[\"num_urls\"]      = tweets[\"content\"].fillna(\"\").str.count(r\"https?://|www\\.\")\ntweets[\"num_mentions\"]  = tweets[\"content\"].fillna(\"\").str.count(r\"@\\w+\")\ntweets[\"num_hashtags\"]  = tweets[\"content\"].fillna(\"\").str.count(r\"#\\w+\")\ntweets[\"text_len\"]      = tweets[\"clean_text\"].str.len()\n\ntweets[[\"content\",\"clean_text\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\"text_len\"]].head(5)\n\n\n\n\n\n\n\n\ncontent\nclean_text\nnum_urls\nnum_mentions\nnum_hashtags\ntext_len\n\n\n\n\n0\n@DiegoPonguill10 @DanielNoboaOk @LuisaGonzalez...\njajajaajajajajajajajajjajaajja okkkkkkk\n0\n3\n0\n39\n\n\n1\n@hectorjalonm @DanielNoboaOk @LuisaGonzalezEc ...\nahora vivimos en la miseria antes fuimos el me...\n0\n3\n0\n71\n\n\n2\n@Gregori58965636 @yesendiaz @DanielNoboaOk Otr...\notro troll basura\n0\n3\n0\n17\n\n\n3\n@jdiegol2010 @DanielNoboaOk https://t.co/CsLWQ...\n\n1\n2\n0\n0\n\n\n4\n@JRamirez2O24 @DanielNoboaOk El tema es respet...\nel tema es respetar a quien eligi el pueblo o no\n0\n2\n0\n48",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#palabras-que-demuestran-apoyo-o-disgusto",
    "href": "LABORATORIO_2.html#palabras-que-demuestran-apoyo-o-disgusto",
    "title": "Laboratorio",
    "section": "Palabras que demuestran apoyo o disgusto",
    "text": "Palabras que demuestran apoyo o disgusto\n\nlex_neg = {\n    \"asco\",\"basura\",\"corrupto\",\"estupido\",\"idiota\",\"ladron\",\"mentiroso\",\"odiar\",\"odio\",\n    \"imbecil\",\"tonto\",\"vomito\",\"repugnante\",\"asqueroso\",\"miserable\"\n}\nlex_pos = {\n    \"apoyo\",\"gracias\",\"excelente\",\"felicitaciones\",\"bien\",\"bravo\",\"genial\",\"mejor\",\n    \"aplaudo\",\"orgullo\",\"feliz\",\"contento\",\"admiro\",\"fuerza\",\"vamos\"\n}\n\ndef count_lexicon_hits(text: str, lexicon: set) -&gt; int:\n    if not text:\n        return 0\n    tokens = word_tokenize(text, language=\"spanish\")\n    return sum(1 for t in tokens if t in lexicon)\n\ntweets[\"neg_count\"] = tweets[\"clean_text\"].apply(lambda t: count_lexicon_hits(t, lex_neg))\ntweets[\"pos_count\"] = tweets[\"clean_text\"].apply(lambda t: count_lexicon_hits(t, lex_pos))\n\ntweets[[\"clean_text\",\"neg_count\",\"pos_count\"]].head(5)\n\n\n\n\n\n\n\n\nclean_text\nneg_count\npos_count\n\n\n\n\n0\njajajaajajajajajajajajjajaajja okkkkkkk\n0\n0\n\n\n1\nahora vivimos en la miseria antes fuimos el me...\n0\n1\n\n\n2\notro troll basura\n1\n0\n\n\n3\n\n0\n0\n\n\n4\nel tema es respetar a quien eligi el pueblo o no\n0\n0",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#creación-de-etiquetas-con-labelencoder",
    "href": "LABORATORIO_2.html#creación-de-etiquetas-con-labelencoder",
    "title": "Laboratorio",
    "section": "Creación de etiquetas con LabelEncoder",
    "text": "Creación de etiquetas con LabelEncoder\n\n# Columnas esperadas, se crean como 0 para evitar errores\ncols_flags = [\"isReply\", \"authorVerified\", \"has_profile_picture\"]\nfor c in cols_flags:\n    if c not in tweets.columns:\n        tweets[c] = 0\n\n# Crear nuevas columnas *_encoded usando LabelEncoder \nfor c in cols_flags:\n    le = LabelEncoder()\n    # Convertimos a string por robustez ante valores no booleanos\n    tweets[f\"{c}_encoded\"] = le.fit_transform(tweets[c].astype(str))\n\ntweets[[f\"{c}_encoded\" for c in cols_flags]].head(5)\n\n\n\n\n\n\n\n\nisReply_encoded\nauthorVerified_encoded\nhas_profile_picture_encoded\n\n\n\n\n0\n0\n0\n1\n\n\n1\n0\n0\n1\n\n\n2\n0\n0\n1\n\n\n3\n0\n0\n1\n\n\n4\n0\n0\n1",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#construcción-de-variable-target-basada-en-caractisticas-de-usuarios",
    "href": "LABORATORIO_2.html#construcción-de-variable-target-basada-en-caractisticas-de-usuarios",
    "title": "Laboratorio",
    "section": "Construcción de variable target basada en caractisticas de usuarios",
    "text": "Construcción de variable target basada en caractisticas de usuarios\n\n# Asegurar columnas numéricas, si no existen, se crean con 0\nnum_needed = [\"account_age_days\", \"time_response\"]\nfor c in num_needed:\n    if c not in tweets.columns:\n        tweets[c] = 0\n\n# Cast numérico seguro\nfor c in [\"account_age_days\",\"time_response\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\n          \"text_len\",\"neg_count\",\"pos_count\",\n          \"isReply_encoded\",\"authorVerified_encoded\",\"has_profile_picture_encoded\"]:\n    tweets[c] = pd.to_numeric(tweets[c], errors=\"coerce\").fillna(0)\n\n# Reglas -&gt; puntos\nscore = np.zeros(len(tweets), dtype=int)\n\nscore += (tweets[\"account_age_days\"] &lt; 30).astype(int)                   # cuenta reciente\nscore += (tweets[\"time_response\"] &lt; 30).astype(int)                      # respuesta muy rápida (ajusta a tu caso)\nscore += (tweets[\"authorVerified_encoded\"] == 0).astype(int)             # no verificada\nscore += (tweets[\"has_profile_picture_encoded\"] == 0).astype(int)        # sin foto\nscore += ((tweets[\"num_urls\"] + tweets[\"num_mentions\"] + tweets[\"num_hashtags\"]) &gt;= 3).astype(int)  # mucho \"ruido\"\nscore += ((tweets[\"neg_count\"] &gt; tweets[\"pos_count\"]) & (tweets[\"neg_count\"] &gt;= 2)).astype(int)     # negatividad marcada\n\n# Umbral: 3 señales o más =&gt; bot\ntweets[\"bots\"] = (score &gt;= 3).astype(int)\n\nprint(\"Distribución de 'bots':\")\nprint(tweets[\"bots\"].value_counts(dropna=False))\n\nDistribución de 'bots':\nbots\n0    147382\n1     11491\nName: count, dtype: int64",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#vectorización-de-texto",
    "href": "LABORATORIO_2.html#vectorización-de-texto",
    "title": "Laboratorio",
    "section": "Vectorización de texto",
    "text": "Vectorización de texto\n\n# Vectorizer sobre 'clean_text' (español)\n# vectorizer = CountVectorizer(stop_words=stop_es) \nvectorizer = TfidfVectorizer(stop_words=stop_es)\nX_text = vectorizer.fit_transform(tweets[\"clean_text\"])\nvocab   = vectorizer.get_feature_names_out()\nprint(\"Matriz TF-IDF:\", X_text.shape)\nprint(\"Ejemplo de vocab:\", vocab[:20])\n\nMatriz TF-IDF: (158873, 57258)\nEjemplo de vocab: ['aa' 'aaa' 'aaaa' 'aaaaa' 'aaaaaa' 'aaaaaaa' 'aaaaaaaa' 'aaaaaaaaaaaaa'\n 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'\n 'aaaaaaasco' 'aaaaaahhhh' 'aaaaaanndaaaaaaa' 'aaaaaauuuuuchhhh' 'aaaaah'\n 'aaaaajajajajaajajajajajajajajaajajajajajajaajajajajajajajaajajajajajajaajajajajajajaja'\n 'aaaah' 'aaaahh' 'aaaahhhajajajajajajajajajajaj' 'aaaahhhh' 'aaaajjjaaa']",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#one-hot-encoder-para-variables-categoricas-método-de-autodetección",
    "href": "LABORATORIO_2.html#one-hot-encoder-para-variables-categoricas-método-de-autodetección",
    "title": "Laboratorio",
    "section": "One hot encoder para variables categoricas (método de autodetección)",
    "text": "One hot encoder para variables categoricas (método de autodetección)\n\n# Detectar automáticamente columnas object para One-Hot (excluyendo 'content'/'clean_text')\nobj_cols = [c for c in tweets.select_dtypes(include=[\"object\"]).columns\n            if c not in {\"content\",\"clean_text\"}]\n\nobj_cols[:10]\n\n['tweetUrl',\n 'replyTo',\n 'createdAt',\n 'authorName',\n 'authorUsername',\n 'authorProfilePic',\n 'authorJoinDate',\n 'source',\n 'hashtags',\n 'mentions']",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#ensamble-númericas-label-ecoder-categóticas-one-hot-encoder-text-columntransformer",
    "href": "LABORATORIO_2.html#ensamble-númericas-label-ecoder-categóticas-one-hot-encoder-text-columntransformer",
    "title": "Laboratorio",
    "section": "Ensamble: númericas (Label Ecoder) + categóticas (One-hot-encoder) + text (columntransformer)",
    "text": "Ensamble: númericas (Label Ecoder) + categóticas (One-hot-encoder) + text (columntransformer)\n\n# Numéricas explícitas (puedes añadir/quitar)\nnum_cols = [\n    \"account_age_days\",\"time_response\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\"text_len\",\n    \"neg_count\",\"pos_count\",\n    # Flags codificados por LabelEncoder (ya son numéricos)\n    \"isReply_encoded\",\"authorVerified_encoded\",\"has_profile_picture_encoded\"\n]\n\n# Algunas podrían no existir (si el dataset original varía)\nnum_cols = [c for c in num_cols if c in tweets.columns]\n\n# Preprocesador\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\",  Pipeline([(\"scaler\", StandardScaler())]), num_cols),\n        (\"cat\",  OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), obj_cols),\n        (\"text\", vectorizer, \"clean_text\"),\n    ],\n    remainder=\"drop\",\n    sparse_threshold=1.0  # mantenemos salida esparza por el bloque texto\n)\n\n# Modelo\nmodel = LogisticRegression(max_iter=1000, class_weight=\"balanced\")  # balanced por si hay desbalance\npipe = Pipeline([\n    (\"prep\", preprocessor),\n    (\"clf\",  model)\n])\n\n# X e y finales\nX = tweets[[\"clean_text\"] + num_cols + obj_cols]  # el CT tomará lo que necesita\ny = tweets[\"bots\"].astype(int)\n\nprint(\"Clases en y:\", dict(y.value_counts()))\n\nClases en y: {0: np.int64(147382), 1: np.int64(11491)}",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#split-división-entrenamiento-y-evaluación",
    "href": "LABORATORIO_2.html#split-división-entrenamiento-y-evaluación",
    "title": "Laboratorio",
    "section": "Split (división), entrenamiento y evaluación",
    "text": "Split (división), entrenamiento y evaluación\nAprende de los tweets (vocabulario) y del ser caso elimina las stop-words\n\n# Si hay 1 sola clase, relajamos umbral de bots para forzar 2 clases (safeguard)\nif y.nunique() &lt; 2:\n    print(\" !!! 'bots' tiene una sola clase con el umbral actual. Bajando el umbral a &gt;=2 señales.\")\n    tweets[\"bots\"] = (score &gt;= 2).astype(int)\n    y = tweets[\"bots\"].astype(int)\n    print(\"Nuevas clases en y:\", dict(y.value_counts()))\n\n# Estratificar solo si hay 2 clases\nstratify_opt = y if y.nunique() &gt; 1 else None\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=stratify_opt\n)\n\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\n\nacc  = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred, zero_division=0)\nrec  = recall_score(y_test, y_pred, zero_division=0)\nf1   = f1_score(y_test, y_pred, zero_division=0)\n\nprint(f\"accuracy:  {acc:.3f}\")\nprint(f\"precision: {prec:.3f}\")\nprint(f\"recall:    {rec:.3f}\")\nprint(f\"f1:        {f1:.3f}\")\n\nprint(\"\\nClassification report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n\naccuracy:  0.952\nprecision: 0.644\nrecall:    0.764\nf1:        0.699\n\nClassification report:\n              precision    recall  f1-score   support\n\n           0       0.98      0.97      0.97     29477\n           1       0.64      0.76      0.70      2298\n\n    accuracy                           0.95     31775\n   macro avg       0.81      0.87      0.84     31775\nweighted avg       0.96      0.95      0.95     31775",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#matriz-de-confusión",
    "href": "LABORATORIO_2.html#matriz-de-confusión",
    "title": "Laboratorio",
    "section": "Matriz de confusión",
    "text": "Matriz de confusión\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#inspección-palabras-más-comunes-tf-idf",
    "href": "LABORATORIO_2.html#inspección-palabras-más-comunes-tf-idf",
    "title": "Laboratorio",
    "section": "Inspección: palabras más comunes (TF-IDF)",
    "text": "Inspección: palabras más comunes (TF-IDF)\n\n# Top términos por TF-IDF medio (en el train)\nfrom scipy.sparse import issparse\n\nX_train_text = pipe.named_steps[\"prep\"].named_transformers_[\"text\"].transform(X_train[\"clean_text\"])\nidf_vocab    = pipe.named_steps[\"prep\"].named_transformers_[\"text\"].get_feature_names_out()\n\n# Promedio por columna\nif issparse(X_train_text):\n    col_means = np.array(X_train_text.mean(axis=0)).ravel()\nelse:\n    col_means = X_train_text.mean(axis=0)\n\ntop_idx = np.argsort(col_means)[::-1][:20]\ntop_terms = [(idf_vocab[i], float(col_means[i])) for i in top_idx]\npd.DataFrame(top_terms, columns=[\"term\",\"mean_tfidf\"])\n\n\n\n\n\n\n\n\nterm\nmean_tfidf\n\n\n\n\n0\nluisa\n0.017463\n\n\n1\npresidente\n0.013639\n\n\n2\nsi\n0.013565\n\n\n3\nnoboa\n0.013282\n\n\n4\nest\n0.012355\n\n\n5\necuador\n0.010876\n\n\n6\npa\n0.009257\n\n\n7\npresidenta\n0.009170\n\n\n8\nser\n0.008616\n\n\n9\nas\n0.007794\n\n\n10\nsolo\n0.007455\n\n\n11\nrana\n0.007120\n\n\n12\nnunca\n0.006444\n\n\n13\nvamos\n0.006277\n\n\n14\nqu\n0.005890\n\n\n15\nbien\n0.005888\n\n\n16\npueblo\n0.005597\n\n\n17\nmejor\n0.005172\n\n\n18\ncorrea\n0.005143\n\n\n19\nrc\n0.005099",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratorio 2 - Módulo de aprendizaje de máquina",
    "section": "",
    "text": "Laboratorio 2\nMódulo de aprendizaje de máquina Yachaytech 2025\nRealizado por: Jorge Delgado",
    "crumbs": [
      "Inicio"
    ]
  }
]