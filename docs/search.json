[
  {
    "objectID": "LABORATORIO_2.html",
    "href": "LABORATORIO_2.html",
    "title": "Laboratorio",
    "section": "",
    "text": "# ====== Importar librerías ======\nimport re\nimport unicodedata\nimport numpy as np\nimport pandas as pd\nimport altair as alt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    classification_report, ConfusionMatrixDisplay\n)\n\n# NLTK\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nnltk.download(\"punkt\", quiet=True)\nnltk.download(\"stopwords\", quiet=True)\nstop_es = stopwords.words(\"spanish\")",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#función-de-limpieza",
    "href": "LABORATORIO_2.html#función-de-limpieza",
    "title": "Laboratorio",
    "section": "Función de limpieza",
    "text": "Función de limpieza\n\ndef normalize_text(text: str) -&gt; str:\n    text = str(text)\n    text = text.lower().strip()\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)  # URLs\n    text = re.sub(r\"@\\w+\", \" \", text)                   # menciones\n    text = re.sub(r\"#\\w+\", \" \", text)                   # hashtags (como texto)\n    text = re.sub(r\"[^a-zñ\\s]\", \" \", text)              # solo letras y espacios\n    text = re.sub(r\"\\s+\", \" \", text).strip()            # espacios extra\n    return text\n\n\ntweets[\"clean_text\"] = tweets[\"content\"].fillna(\"\").astype(str).apply(normalize_text)\n\n# Creación de algunas features simples de texto\ntweets[\"num_urls\"]      = tweets[\"content\"].fillna(\"\").str.count(r\"https?://|www\\.\")\ntweets[\"num_mentions\"]  = tweets[\"content\"].fillna(\"\").str.count(r\"@\\w+\")\ntweets[\"num_hashtags\"]  = tweets[\"content\"].fillna(\"\").str.count(r\"#\\w+\")\ntweets[\"text_len\"]      = tweets[\"clean_text\"].str.len()\n\ntweets[[\"content\",\"clean_text\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\"text_len\"]].head(5)\n\n\n\n\n\n\n\n\ncontent\nclean_text\nnum_urls\nnum_mentions\nnum_hashtags\ntext_len\n\n\n\n\n0\n@DiegoPonguill10 @DanielNoboaOk @LuisaGonzalez...\njajajaajajajajajajajajjajaajja okkkkkkk\n0\n3\n0\n39\n\n\n1\n@hectorjalonm @DanielNoboaOk @LuisaGonzalezEc ...\nahora vivimos en la miseria antes fuimos el me...\n0\n3\n0\n71\n\n\n2\n@Gregori58965636 @yesendiaz @DanielNoboaOk Otr...\notro troll basura\n0\n3\n0\n17\n\n\n3\n@jdiegol2010 @DanielNoboaOk https://t.co/CsLWQ...\n\n1\n2\n0\n0\n\n\n4\n@JRamirez2O24 @DanielNoboaOk El tema es respet...\nel tema es respetar a quien eligi el pueblo o no\n0\n2\n0\n48",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#palabras-que-demuestran-apoyo-o-disgusto",
    "href": "LABORATORIO_2.html#palabras-que-demuestran-apoyo-o-disgusto",
    "title": "Laboratorio",
    "section": "Palabras que demuestran apoyo o disgusto",
    "text": "Palabras que demuestran apoyo o disgusto\n\nlex_neg = {\n    \"asco\",\"basura\",\"corrupto\",\"estupido\",\"idiota\",\"ladron\",\"mentiroso\",\"odiar\",\"odio\",\n    \"imbecil\",\"tonto\",\"vomito\",\"repugnante\",\"asqueroso\",\"miserable\"\n}\nlex_pos = {\n    \"apoyo\",\"gracias\",\"excelente\",\"felicitaciones\",\"bien\",\"bravo\",\"genial\",\"mejor\",\n    \"aplaudo\",\"orgullo\",\"feliz\",\"contento\",\"admiro\",\"fuerza\",\"vamos\"\n}\n\ndef count_lexicon_hits(text: str, lexicon: set) -&gt; int:\n    if not text:\n        return 0\n    tokens = word_tokenize(text, language=\"spanish\")\n    return sum(1 for t in tokens if t in lexicon)\n\ntweets[\"neg_count\"] = tweets[\"clean_text\"].apply(lambda t: count_lexicon_hits(t, lex_neg))\ntweets[\"pos_count\"] = tweets[\"clean_text\"].apply(lambda t: count_lexicon_hits(t, lex_pos))\n\ntweets[[\"clean_text\",\"neg_count\",\"pos_count\"]].head(5)\n\n\n\n\n\n\n\n\nclean_text\nneg_count\npos_count\n\n\n\n\n0\njajajaajajajajajajajajjajaajja okkkkkkk\n0\n0\n\n\n1\nahora vivimos en la miseria antes fuimos el me...\n0\n1\n\n\n2\notro troll basura\n1\n0\n\n\n3\n\n0\n0\n\n\n4\nel tema es respetar a quien eligi el pueblo o no\n0\n0",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#creación-de-etiquetas-con-labelencoder",
    "href": "LABORATORIO_2.html#creación-de-etiquetas-con-labelencoder",
    "title": "Laboratorio",
    "section": "Creación de etiquetas con LabelEncoder",
    "text": "Creación de etiquetas con LabelEncoder\n\n# Columnas esperadas, se crean como 0 para evitar errores\ncols_flags = [\"isReply\", \"authorVerified\", \"has_profile_picture\"]\nfor c in cols_flags:\n    if c not in tweets.columns:\n        tweets[c] = 0\n\n# Crear nuevas columnas *_encoded usando LabelEncoder \nfor c in cols_flags:\n    le = LabelEncoder()\n    # Convertimos a string por robustez ante valores no booleanos\n    tweets[f\"{c}_encoded\"] = le.fit_transform(tweets[c].astype(str))\n\ntweets[[f\"{c}_encoded\" for c in cols_flags]].head(5)\n\n\n\n\n\n\n\n\nisReply_encoded\nauthorVerified_encoded\nhas_profile_picture_encoded\n\n\n\n\n0\n0\n0\n1\n\n\n1\n0\n0\n1\n\n\n2\n0\n0\n1\n\n\n3\n0\n0\n1\n\n\n4\n0\n0\n1",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#construcción-de-variable-target-basada-en-caractisticas-de-usuarios",
    "href": "LABORATORIO_2.html#construcción-de-variable-target-basada-en-caractisticas-de-usuarios",
    "title": "Laboratorio",
    "section": "Construcción de variable target basada en caractisticas de usuarios",
    "text": "Construcción de variable target basada en caractisticas de usuarios\n\n# Asegurar columnas numéricas, si no existen, se crean con 0\nnum_needed = [\"account_age_days\", \"time_response\"]\nfor c in num_needed:\n    if c not in tweets.columns:\n        tweets[c] = 0\n\n# Cast numérico seguro\nfor c in [\"account_age_days\",\"time_response\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\n          \"text_len\",\"neg_count\",\"pos_count\",\n          \"isReply_encoded\",\"authorVerified_encoded\",\"has_profile_picture_encoded\"]:\n    tweets[c] = pd.to_numeric(tweets[c], errors=\"coerce\").fillna(0)\n\n# Reglas -&gt; puntos\nscore = np.zeros(len(tweets), dtype=int)\n\nscore += (tweets[\"account_age_days\"] &lt; 30).astype(int)                   # cuenta reciente\nscore += (tweets[\"time_response\"] &lt; 30).astype(int)                      # respuesta muy rápida (ajusta a tu caso)\nscore += (tweets[\"authorVerified_encoded\"] == 0).astype(int)             # no verificada\nscore += (tweets[\"has_profile_picture_encoded\"] == 0).astype(int)        # sin foto\nscore += ((tweets[\"num_urls\"] + tweets[\"num_mentions\"] + tweets[\"num_hashtags\"]) &gt;= 3).astype(int)  # mucho \"ruido\"\nscore += ((tweets[\"neg_count\"] &gt; tweets[\"pos_count\"]) & (tweets[\"neg_count\"] &gt;= 2)).astype(int)     # negatividad marcada\n\n# Umbral: 3 señales o más =&gt; bot\ntweets[\"bots\"] = (score &gt;= 3).astype(int)\n\nprint(\"Distribución de 'bots':\")\nprint(tweets[\"bots\"].value_counts(dropna=False))\n\nDistribución de 'bots':\nbots\n0    147382\n1     11491\nName: count, dtype: int64",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#vectorización-de-texto",
    "href": "LABORATORIO_2.html#vectorización-de-texto",
    "title": "Laboratorio",
    "section": "Vectorización de texto",
    "text": "Vectorización de texto\n\n# Vectorizer sobre 'clean_text' (español)\n# vectorizer = CountVectorizer(stop_words=stop_es) \nvectorizer = TfidfVectorizer(stop_words=stop_es)\nX_text = vectorizer.fit_transform(tweets[\"clean_text\"])\nvocab   = vectorizer.get_feature_names_out()\nprint(\"Matriz TF-IDF:\", X_text.shape)\nprint(\"Ejemplo de vocab:\", vocab[:20])\n\nMatriz TF-IDF: (158873, 57258)\nEjemplo de vocab: ['aa' 'aaa' 'aaaa' 'aaaaa' 'aaaaaa' 'aaaaaaa' 'aaaaaaaa' 'aaaaaaaaaaaaa'\n 'aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa'\n 'aaaaaaasco' 'aaaaaahhhh' 'aaaaaanndaaaaaaa' 'aaaaaauuuuuchhhh' 'aaaaah'\n 'aaaaajajajajaajajajajajajajajaajajajajajajaajajajajajajajaajajajajajajaajajajajajajaja'\n 'aaaah' 'aaaahh' 'aaaahhhajajajajajajajajajajaj' 'aaaahhhh' 'aaaajjjaaa']",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#one-hot-encoder-para-variables-categoricas-método-de-autodetección",
    "href": "LABORATORIO_2.html#one-hot-encoder-para-variables-categoricas-método-de-autodetección",
    "title": "Laboratorio",
    "section": "One hot encoder para variables categoricas (método de autodetección)",
    "text": "One hot encoder para variables categoricas (método de autodetección)\n\n# Detectar automáticamente columnas object para One-Hot (excluyendo 'content'/'clean_text')\nobj_cols = [c for c in tweets.select_dtypes(include=[\"object\"]).columns\n            if c not in {\"content\",\"clean_text\"}]\n\nobj_cols[:10]\n\n['tweetUrl',\n 'replyTo',\n 'createdAt',\n 'authorName',\n 'authorUsername',\n 'authorProfilePic',\n 'authorJoinDate',\n 'source',\n 'hashtags',\n 'mentions']",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#ensamble-númericas-label-ecoder-categóticas-one-hot-encoder-text-columntransformer",
    "href": "LABORATORIO_2.html#ensamble-númericas-label-ecoder-categóticas-one-hot-encoder-text-columntransformer",
    "title": "Laboratorio",
    "section": "Ensamble: númericas (Label Ecoder) + categóticas (One-hot-encoder) + text (columntransformer)",
    "text": "Ensamble: númericas (Label Ecoder) + categóticas (One-hot-encoder) + text (columntransformer)\n\n# Numéricas explícitas (puedes añadir/quitar)\nnum_cols = [\n    \"account_age_days\",\"time_response\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\"text_len\",\n    \"neg_count\",\"pos_count\",\n    # Flags codificados por LabelEncoder (ya son numéricos)\n    \"isReply_encoded\",\"authorVerified_encoded\",\"has_profile_picture_encoded\"\n]\n\n# Algunas podrían no existir (si el dataset original varía)\nnum_cols = [c for c in num_cols if c in tweets.columns]\n\n# Preprocesador\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\",  Pipeline([(\"scaler\", StandardScaler())]), num_cols),\n        (\"cat\",  OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), obj_cols),\n        (\"text\", vectorizer, \"clean_text\"),\n    ],\n    remainder=\"drop\",\n    sparse_threshold=1.0  # mantenemos salida esparza por el bloque texto\n)\n\n# Modelo\nmodel = LogisticRegression(max_iter=1000, class_weight=\"balanced\")  # balanced por si hay desbalance\npipe = Pipeline([\n    (\"prep\", preprocessor),\n    (\"clf\",  model)\n])\n\n# X e y finales\nX = tweets[[\"clean_text\"] + num_cols + obj_cols]  # el CT tomará lo que necesita\ny = tweets[\"bots\"].astype(int)\n\nprint(\"Clases en y:\", dict(y.value_counts()))\n\nClases en y: {0: np.int64(147382), 1: np.int64(11491)}",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#split-división-entrenamiento-y-evaluación",
    "href": "LABORATORIO_2.html#split-división-entrenamiento-y-evaluación",
    "title": "Laboratorio",
    "section": "Split (división), entrenamiento y evaluación",
    "text": "Split (división), entrenamiento y evaluación\nAprende de los tweets (vocabulario) y del ser caso elimina las stop-words\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\n\nacc  = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred, zero_division=0)\nrec  = recall_score(y_test, y_pred, zero_division=0)\nf1   = f1_score(y_test, y_pred, zero_division=0)\n\nprint(f\"accuracy:  {acc:.3f}\")\nprint(f\"precision: {prec:.3f}\")\nprint(f\"recall:    {rec:.3f}\")\nprint(f\"f1:        {f1:.3f}\")\n\nprint(\"\\nClassification report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n\naccuracy:  0.951\nprecision: 0.640\nrecall:    0.782\nf1:        0.704\n\nClassification report:\n              precision    recall  f1-score   support\n\n           0       0.98      0.96      0.97     29408\n           1       0.64      0.78      0.70      2367\n\n    accuracy                           0.95     31775\n   macro avg       0.81      0.87      0.84     31775\nweighted avg       0.96      0.95      0.95     31775",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#matriz-de-confusión",
    "href": "LABORATORIO_2.html#matriz-de-confusión",
    "title": "Laboratorio",
    "section": "Matriz de confusión",
    "text": "Matriz de confusión\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#inspección-palabras-más-comunes-tf-idf",
    "href": "LABORATORIO_2.html#inspección-palabras-más-comunes-tf-idf",
    "title": "Laboratorio",
    "section": "Inspección: palabras más comunes (TF-IDF)",
    "text": "Inspección: palabras más comunes (TF-IDF)\n\n# Top términos por TF-IDF medio (en el train)\nfrom scipy.sparse import issparse\n\nX_train_text = pipe.named_steps[\"prep\"].named_transformers_[\"text\"].transform(X_train[\"clean_text\"])\nidf_vocab    = pipe.named_steps[\"prep\"].named_transformers_[\"text\"].get_feature_names_out()\n\n# Promedio por columna\nif issparse(X_train_text):\n    col_means = np.array(X_train_text.mean(axis=0)).ravel()\nelse:\n    col_means = X_train_text.mean(axis=0)\n\ntop_idx = np.argsort(col_means)[::-1][:20]\ntop_terms = [(idf_vocab[i], float(col_means[i])) for i in top_idx]\npd.DataFrame(top_terms, columns=[\"term\",\"mean_tfidf\"])\n\n\n\n\n\n\n\n\nterm\nmean_tfidf\n\n\n\n\n0\nluisa\n0.017571\n\n\n1\npresidente\n0.013736\n\n\n2\nsi\n0.013674\n\n\n3\nnoboa\n0.013436\n\n\n4\nest\n0.012366\n\n\n5\necuador\n0.010899\n\n\n6\npa\n0.009313\n\n\n7\npresidenta\n0.009178\n\n\n8\nser\n0.008642\n\n\n9\nas\n0.007840\n\n\n10\nsolo\n0.007504\n\n\n11\nrana\n0.006959\n\n\n12\nnunca\n0.006466\n\n\n13\nvamos\n0.006268\n\n\n14\nbien\n0.005931\n\n\n15\nqu\n0.005899\n\n\n16\npueblo\n0.005612\n\n\n17\ncorrea\n0.005187\n\n\n18\nmejor\n0.005187\n\n\n19\ngente\n0.005059",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratorio 2 - Módulo de aprendizaje de máquina",
    "section": "",
    "text": "Laboratorio 2\nMódulo de aprendizaje de máquina Yachaytech 2025\nRealizado por: Jorge Delgado",
    "crumbs": [
      "Inicio"
    ]
  },
  {
    "objectID": "Proyecto_final.html",
    "href": "Proyecto_final.html",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport re, ast\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n    classification_report, ConfusionMatrixDisplay,\n    mean_absolute_error, mean_squared_error, r2_score,\n    silhouette_score\n)\nfrom sklearn.cluster import KMeans\n\n# Ruta al CSV (deja el archivo en la misma carpeta que este .qmd)\ndf = pd.read_csv(\"data/1500_tweets_con_toxicity.csv\", encoding=\"utf-8\")\ndf.head()\n\n\n\n\n\n\n\n\n\ntweetId\ntweetUrl\ncontent\nisReply\nreplyTo\ncreatedAt\nauthorId\nauthorName\nauthorUsername\nauthorVerified\n...\ninReplyToId\nDate\ntime_response\naccount_age_days\nmentions_count\nhashtags_count\ncontent_length\nhas_profile_picture\nsentiment_polarity\ntoxicity_score\n\n\n\n\n0\n1878630970745900800\nhttps://x.com/Pableins15/status/18786309707459...\n@DanielNoboaOk @DiegoBorjaPC Lávate el hocico ...\nTrue\nDanielNoboaOk\n2025-01-13 02:31:00\n176948611\nPablo Balarezo\nPableins15\nFalse\n...\n1878539079249547520\n2025-01-12 20:26:32\n364.466667\n5261\n2\n0\n309\nFalse\n0.0\n0.543256\n\n\n1\n1904041877503984128\nhttps://x.com/solma1201/status/190404187750398...\n@DanielNoboaOk De esa arrastrada no te levanta...\nTrue\nDanielNoboaOk\n2025-03-24 05:25:00\n1368663286582030336\nSolma1201\nsolma1201\nFalse\n...\n1904003201143115776\n2025-03-24 02:51:52\n153.133333\n1399\n1\n0\n70\nTrue\n0.0\n0.426917\n\n\n2\n1877463444649046016\nhttps://x.com/Mediterran67794/status/187746344...\n@LuisaGonzalezEc @RC5Oficial Protegiendo a los...\nTrue\nLuisaGonzalezEc\n2025-01-09 21:12:00\n1851005619106451712\nMédico Escritor Filósofo Hermeneútico\nMediterran67794\nFalse\n...\n1877158437236228352\n2025-01-09 01:00:22\n1211.633333\n68\n2\n0\n122\nTrue\n0.0\n0.555970\n\n\n3\n1881356046108885248\nhttps://x.com/ardededa/status/1881356046108885494\n@DanielNoboaOk #NoboaPresidente. Todo 7!\nTrue\nDanielNoboaOk\n2025-01-20 15:00:00\n315799544\nDenise\nardededa\nFalse\n...\n1881165128185560832\n2025-01-20 02:21:31\n758.483333\n4955\n1\n0\n41\nTrue\n0.0\n0.046615\n\n\n4\n1888331962063978752\nhttps://x.com/LMarquinezm/status/1888331962063...\n@slider1908 @LuisaGonzalezEc @DianaAtamaint @c...\nTrue\nslider1908\n2025-02-08 20:59:00\n1551883554\nLuis Marquínez\nLMarquinezm\nFalse\n...\n1888256000085397504\n2025-02-08 14:59:07\n359.883333\n4208\n5\n0\n101\nTrue\n0.0\n0.846027\n\n\n\n\n5 rows × 27 columns"
  },
  {
    "objectID": "Proyecto_final.html#preparación",
    "href": "Proyecto_final.html#preparación",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport re, ast\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n    classification_report, ConfusionMatrixDisplay,\n    mean_absolute_error, mean_squared_error, r2_score,\n    silhouette_score\n)\nfrom sklearn.cluster import KMeans\n\n# Ruta al CSV (deja el archivo en la misma carpeta que este .qmd)\ndf = pd.read_csv(\"data/1500_tweets_con_toxicity.csv\", encoding=\"utf-8\")\ndf.head()\n\n\n\n\n\n\n\n\n\ntweetId\ntweetUrl\ncontent\nisReply\nreplyTo\ncreatedAt\nauthorId\nauthorName\nauthorUsername\nauthorVerified\n...\ninReplyToId\nDate\ntime_response\naccount_age_days\nmentions_count\nhashtags_count\ncontent_length\nhas_profile_picture\nsentiment_polarity\ntoxicity_score\n\n\n\n\n0\n1878630970745900800\nhttps://x.com/Pableins15/status/18786309707459...\n@DanielNoboaOk @DiegoBorjaPC Lávate el hocico ...\nTrue\nDanielNoboaOk\n2025-01-13 02:31:00\n176948611\nPablo Balarezo\nPableins15\nFalse\n...\n1878539079249547520\n2025-01-12 20:26:32\n364.466667\n5261\n2\n0\n309\nFalse\n0.0\n0.543256\n\n\n1\n1904041877503984128\nhttps://x.com/solma1201/status/190404187750398...\n@DanielNoboaOk De esa arrastrada no te levanta...\nTrue\nDanielNoboaOk\n2025-03-24 05:25:00\n1368663286582030336\nSolma1201\nsolma1201\nFalse\n...\n1904003201143115776\n2025-03-24 02:51:52\n153.133333\n1399\n1\n0\n70\nTrue\n0.0\n0.426917\n\n\n2\n1877463444649046016\nhttps://x.com/Mediterran67794/status/187746344...\n@LuisaGonzalezEc @RC5Oficial Protegiendo a los...\nTrue\nLuisaGonzalezEc\n2025-01-09 21:12:00\n1851005619106451712\nMédico Escritor Filósofo Hermeneútico\nMediterran67794\nFalse\n...\n1877158437236228352\n2025-01-09 01:00:22\n1211.633333\n68\n2\n0\n122\nTrue\n0.0\n0.555970\n\n\n3\n1881356046108885248\nhttps://x.com/ardededa/status/1881356046108885494\n@DanielNoboaOk #NoboaPresidente. Todo 7!\nTrue\nDanielNoboaOk\n2025-01-20 15:00:00\n315799544\nDenise\nardededa\nFalse\n...\n1881165128185560832\n2025-01-20 02:21:31\n758.483333\n4955\n1\n0\n41\nTrue\n0.0\n0.046615\n\n\n4\n1888331962063978752\nhttps://x.com/LMarquinezm/status/1888331962063...\n@slider1908 @LuisaGonzalezEc @DianaAtamaint @c...\nTrue\nslider1908\n2025-02-08 20:59:00\n1551883554\nLuis Marquínez\nLMarquinezm\nFalse\n...\n1888256000085397504\n2025-02-08 14:59:07\n359.883333\n4208\n5\n0\n101\nTrue\n0.0\n0.846027\n\n\n\n\n5 rows × 27 columns"
  },
  {
    "objectID": "Proyecto_final.html#eda",
    "href": "Proyecto_final.html#eda",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "2 1. EDA",
    "text": "2 1. EDA\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 27 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   tweetId              1500 non-null   int64  \n 1   tweetUrl             1500 non-null   object \n 2   content              1500 non-null   object \n 3   isReply              1500 non-null   bool   \n 4   replyTo              1490 non-null   object \n 5   createdAt            1500 non-null   object \n 6   authorId             1500 non-null   int64  \n 7   authorName           1500 non-null   object \n 8   authorUsername       1500 non-null   object \n 9   authorVerified       1500 non-null   bool   \n 10  authorFollowers      1500 non-null   int64  \n 11  authorProfilePic     1500 non-null   object \n 12  authorJoinDate       1500 non-null   object \n 13  source               1500 non-null   object \n 14  hashtags             121 non-null    object \n 15  mentions             1499 non-null   object \n 16  conversationId       1500 non-null   int64  \n 17  inReplyToId          1500 non-null   int64  \n 18  Date                 1500 non-null   object \n 19  time_response        1500 non-null   float64\n 20  account_age_days     1500 non-null   int64  \n 21  mentions_count       1500 non-null   int64  \n 22  hashtags_count       1500 non-null   int64  \n 23  content_length       1500 non-null   int64  \n 24  has_profile_picture  1500 non-null   bool   \n 25  sentiment_polarity   1500 non-null   float64\n 26  toxicity_score       1347 non-null   float64\ndtypes: bool(3), float64(3), int64(9), object(12)\nmemory usage: 285.8+ KB\n\n\n\n\nCode\n# Resumen numérico\ndf.describe(include=\"number\").T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntweetId\n1500.0\n1.893421e+18\n1.166584e+16\n1.876011e+18\n1.883283e+18\n1.887876e+18\n1.904588e+18\n1.922145e+18\n\n\nauthorId\n1500.0\n9.838015e+17\n7.900284e+17\n1.159021e+06\n9.690383e+08\n1.318014e+18\n1.710233e+18\n1.908229e+18\n\n\nauthorFollowers\n1500.0\n3.625721e+03\n1.184447e+05\n0.000000e+00\n7.000000e+00\n4.300000e+01\n1.992500e+02\n4.577730e+06\n\n\nconversationId\n1500.0\n1.893127e+18\n1.161854e+16\n1.876001e+18\n1.883238e+18\n1.887344e+18\n1.904198e+18\n1.910014e+18\n\n\ninReplyToId\n1500.0\n1.893147e+18\n1.162094e+16\n1.876001e+18\n1.883238e+18\n1.887355e+18\n1.904234e+18\n1.910015e+18\n\n\ntime_response\n1500.0\n1.170038e+03\n3.273930e+03\n1.333333e-01\n1.363000e+02\n5.156250e+02\n1.265717e+03\n6.356900e+04\n\n\naccount_age_days\n1500.0\n2.271134e+03\n1.984157e+03\n-9.000000e+01\n4.557500e+02\n1.538000e+03\n4.420750e+03\n6.506000e+03\n\n\nmentions_count\n1500.0\n1.723333e+00\n9.462483e-01\n0.000000e+00\n1.000000e+00\n2.000000e+00\n2.000000e+00\n1.000000e+01\n\n\nhashtags_count\n1500.0\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n\n\ncontent_length\n1500.0\n1.165280e+02\n7.749371e+01\n1.700000e+01\n5.700000e+01\n9.600000e+01\n1.500000e+02\n6.840000e+02\n\n\nsentiment_polarity\n1500.0\n-7.906765e-03\n1.197964e-01\n-1.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n1.000000e+00\n\n\ntoxicity_score\n1347.0\n2.538788e-01\n2.439420e-01\n1.939886e-03\n2.844395e-02\n1.883923e-01\n4.269174e-01\n9.391453e-01\n\n\n\n\n\n\n\n\n\nCode\n# Resumen categórico\ndf.select_dtypes(exclude=\"number\").nunique().sort_values(ascending=False).head(20)\n\n\ntweetUrl               1500\ncontent                1491\ncreatedAt              1460\nauthorUsername         1386\nauthorJoinDate         1386\nauthorName             1375\nauthorProfilePic       1322\nDate                    382\nmentions                340\nreplyTo                 240\nhashtags                 83\nhas_profile_picture       2\nisReply                   1\nsource                    1\nauthorVerified            1\ndtype: int64\n\n\n\n\nCode\n# Nulos y duplicados\nmissing = df.isna().sum().sort_values(ascending=False).to_frame(\"n_missing\")\nmissing[\"pct\"] = (df.isna().mean()*100).sort_values(ascending=False)\nmissing.head(10)\n\n\n\n\n\n\n\n\n\nn_missing\npct\n\n\n\n\nhashtags\n1379\n91.933333\n\n\ntoxicity_score\n153\n10.200000\n\n\nreplyTo\n10\n0.666667\n\n\nmentions\n1\n0.066667\n\n\ncontent\n0\n0.000000\n\n\ncreatedAt\n0\n0.000000\n\n\nauthorId\n0\n0.000000\n\n\nauthorName\n0\n0.000000\n\n\nisReply\n0\n0.000000\n\n\ntweetUrl\n0\n0.000000\n\n\n\n\n\n\n\n\n\nCode\n# Distribución toxicity_score\ndf[\"toxicity_score\"] = pd.to_numeric(df[\"toxicity_score\"], errors=\"coerce\")\ndf[\"toxicity_score\"].dropna().hist(bins=30)\nplt.title(\"Distribución de toxicity_score\")\nplt.xlabel(\"toxicity_score\"); plt.ylabel(\"Frecuencia\"); plt.show()\n\ndf[\"toxicity_score\"].describe(percentiles=[0.1,0.25,0.5,0.75,0.9,0.95])\n\n\n\n\n\n\n\n\n\ncount    1347.000000\nmean        0.253879\nstd         0.243942\nmin         0.001940\n10%         0.006333\n25%         0.028444\n50%         0.188392\n75%         0.426917\n90%         0.602753\n95%         0.749544\nmax         0.939145\nName: toxicity_score, dtype: float64\n\n\n\n\nCode\n# Boxplots de numéricas clave\nnum_cols = [\"authorFollowers\", \"time_response\", \"account_age_days\", \"mentions_count\", \"hashtags_count\", \"content_length\", \"sentiment_polarity\"]\npresent = [c for c in num_cols if c in df.columns]\ndf[present].boxplot(rot=45); plt.title(\"Boxplots numéricos\"); plt.tight_layout(); plt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Top hashtags y menciones\ndef parse_list_like(x):\n    if pd.isna(x): return []\n    s = str(x).strip()\n    try:\n        obj = ast.literal_eval(s)\n        if isinstance(obj, list):\n            return [str(t).strip().lower() for t in obj if str(t).strip()]\n    except Exception:\n        pass\n    s = re.sub(r\"[\\[\\]{}()'\\\"#]\", \" \", s)\n    tokens = re.split(r\"[,\\s]+\", s)\n    return [t.strip().lower() for t in tokens if t.strip()]\n\nfor col, title in [(\"hashtags\",\"Top hashtags\"), (\"mentions\",\"Top menciones\")]:\n    if col in df.columns:\n        items = []\n        for v in df[col]:\n            items.extend(parse_list_like(v))\n        if items:\n            top = pd.Series(items).value_counts().head(20)\n            top.sort_values(ascending=True).plot(kind=\"barh\"); plt.title(title); plt.tight_layout(); plt.show()\n            display(top.to_frame(\"count\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncount\n\n\n\n\nluisapresidenta\n38\n\n\nluisaporlavida\n19\n\n\nrevivirecuador\n16\n\n\nnoboanuncamás\n10\n\n\nluisaeslaesperanza\n7\n\n\nluisagonzálezpresidenta\n5\n\n\ngdorc5\n4\n\n\nluisaaprendearespetar\n4\n\n\nnuncamas\n4\n\n\nelecciones2025ec\n4\n\n\ncambioseguro\n4\n\n\ndebatepresidencial\n4\n\n\nnoboanoseraspresidente\n3\n\n\nnoboaescorrupción\n3\n\n\nranarené\n3\n\n\nluisadesdolariza\n3\n\n\necuadordebate\n2\n\n\necuadorconnoboa\n2\n\n\nrcnuncamas\n2\n\n\ncorreismo\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncount\n\n\n\n\n@luisagonzalezec\n975\n\n\n@danielnoboaok\n561\n\n\n@rc5oficial\n333\n\n\n@diegoborjapc\n54\n\n\n@ffaaecuador\n33\n\n\n@mashirafael\n30\n\n\n@cnegobec\n28\n\n\n@dianaatamaint\n26\n\n\n@cnnee\n15\n\n\n@soyfdelrincon\n14\n\n\n@ecuarauz\n13\n\n\n@aquilesalvarez\n12\n\n\n@mariacorinaya\n11\n\n\n@soybelenix\n10\n\n\n@aguschmer\n6\n\n\n@asambleaecuador\n6\n\n\n@chrisviteri\n5\n\n\n@janethinostroza\n5\n\n\n@bancomundial\n5\n\n\n@ricardopatinoec\n5\n\n\n\n\n\n\n\nHallazgos clave (EDA):\n- Distribución de toxicity_score con mediana, cuartiles y % de valores altos.\n- Campos con nulos relevantes (p.ej. toxicity_score y hashtags).\n- Concentración de polaridad y relación preliminar con la toxicidad."
  },
  {
    "objectID": "Proyecto_final.html#preprocesamiento-y-codificación",
    "href": "Proyecto_final.html#preprocesamiento-y-codificación",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "3 2. Preprocesamiento y codificación",
    "text": "3 2. Preprocesamiento y codificación\n\n\nCode\ntext_col = \"content\"\nnum_cols = [\"authorFollowers\", \"account_age_days\", \"mentions_count\", \"hashtags_count\", \"content_length\", \"sentiment_polarity\"]\ncat_cols = [\"source\", \"has_profile_picture\"]\n\n# Subconjunto para modelado\ndf_model = df[[text_col, \"toxicity_score\"] + num_cols + cat_cols].copy()\nfor c in num_cols:\n    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\")\nfor c in cat_cols:\n    df_model[c] = df_model[c].astype(\"category\")\ndf_model = df_model.dropna(subset=[text_col, \"toxicity_score\"]).reset_index(drop=True)\n\nX = df_model[[text_col] + num_cols + cat_cols]\ny_cont = df_model[\"toxicity_score\"]\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"text\", TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1,2), strip_accents=\"unicode\"), text_col),\n        (\"num\", Pipeline([(\"scaler\", StandardScaler(with_mean=False))]), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    ]\n)\npreprocessor\n\n\nColumnTransformer(transformers=[('text',\n                                 TfidfVectorizer(max_df=0.9, min_df=5,\n                                                 ngram_range=(1, 2),\n                                                 strip_accents='unicode'),\n                                 'content'),\n                                ('num',\n                                 Pipeline(steps=[('scaler',\n                                                  StandardScaler(with_mean=False))]),\n                                 ['authorFollowers', 'account_age_days',\n                                  'mentions_count', 'hashtags_count',\n                                  'content_length', 'sentiment_polarity']),\n                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n                                 ['source', 'has_profile_picture'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriNot fitted\n        \n            \n                Parameters\n                \n\n\n\n\ntransformers \n[('text', ...), ('num', ...), ...]\n\n\n\nremainder \n'drop'\n\n\n\nsparse_threshold \n0.3\n\n\n\nn_jobs \nNone\n\n\n\ntransformer_weights \nNone\n\n\n\nverbose \nFalse\n\n\n\nverbose_feature_names_out \nTrue\n\n\n\nforce_int_remainder_cols \n'deprecated'\n\n\n\n\n            \n        \n    textcontentTfidfVectorizer?Documentation for TfidfVectorizer\n        \n            \n                Parameters\n                \n\n\n\n\ninput \n'content'\n\n\n\nencoding \n'utf-8'\n\n\n\ndecode_error \n'strict'\n\n\n\nstrip_accents \n'unicode'\n\n\n\nlowercase \nTrue\n\n\n\npreprocessor \nNone\n\n\n\ntokenizer \nNone\n\n\n\nanalyzer \n'word'\n\n\n\nstop_words \nNone\n\n\n\ntoken_pattern \n'(?u)\\\\b\\\\w\\\\w+\\\\b'\n\n\n\nngram_range \n(1, ...)\n\n\n\nmax_df \n0.9\n\n\n\nmin_df \n5\n\n\n\nmax_features \nNone\n\n\n\nvocabulary \nNone\n\n\n\nbinary \nFalse\n\n\n\ndtype \n&lt;class 'numpy.float64'&gt;\n\n\n\nnorm \n'l2'\n\n\n\nuse_idf \nTrue\n\n\n\nsmooth_idf \nTrue\n\n\n\nsublinear_tf \nFalse\n\n\n\n\n            \n        \n    num['authorFollowers', 'account_age_days', 'mentions_count', 'hashtags_count', 'content_length', 'sentiment_polarity']StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\ncopy \nTrue\n\n\n\nwith_mean \nFalse\n\n\n\nwith_std \nTrue\n\n\n\n\n            \n        \n    cat['source', 'has_profile_picture']OneHotEncoder?Documentation for OneHotEncoder\n        \n            \n                Parameters\n                \n\n\n\n\ncategories \n'auto'\n\n\n\ndrop \nNone\n\n\n\nsparse_output \nTrue\n\n\n\ndtype \n&lt;class 'numpy.float64'&gt;\n\n\n\nhandle_unknown \n'ignore'\n\n\n\nmin_frequency \nNone\n\n\n\nmax_categories \nNone\n\n\n\nfeature_name_combiner \n'concat'"
  },
  {
    "objectID": "Proyecto_final.html#clasificación",
    "href": "Proyecto_final.html#clasificación",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "4 3. Clasificación",
    "text": "4 3. Clasificación\n\n\nCode\n# Target binario con umbral 0.5 (puedes justificar 0.5 vs 0.7 en el informe)\ny_bin = (y_cont &gt;= 0.5).astype(int)\nX_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, random_state=42, stratify=y_bin)\n\npipe_clf = Pipeline([(\"preprocess\", preprocessor),\n                     (\"clf\", LogisticRegression(max_iter=300, solver=\"liblinear\", class_weight=\"balanced\"))])\n\npipe_clf.fit(X_train, y_train)\ny_pred = pipe_clf.predict(X_test)\ny_proba = pipe_clf.predict_proba(X_test)[:,1]\n\nmetrics = {\n    \"accuracy\": accuracy_score(y_test, y_pred),\n    \"precision\": precision_score(y_test, y_pred, zero_division=0),\n    \"recall\": recall_score(y_test, y_pred, zero_division=0),\n    \"f1\": f1_score(y_test, y_pred, zero_division=0),\n    \"roc_auc\": roc_auc_score(y_test, y_proba),\n}\nmetrics\n\n\n{'accuracy': 0.774074074074074,\n 'precision': 0.4189189189189189,\n 'recall': 0.6326530612244898,\n 'f1': 0.5040650406504065,\n 'roc_auc': 0.7599039615846338}\n\n\n\n\nCode\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)\nplt.title(\"Matriz de confusión - Clasificación\"); plt.tight_layout(); plt.show()"
  },
  {
    "objectID": "Proyecto_final.html#regresión",
    "href": "Proyecto_final.html#regresión",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "5 4. Regresión",
    "text": "5 4. Regresión\n\n\nCode\nX_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y_cont, test_size=0.2, random_state=42)\n\npipe_reg = Pipeline([(\"preprocess\", preprocessor), (\"reg\", LinearRegression())])\npipe_reg.fit(X_train_r, y_train_r)\ny_pred_r = pipe_reg.predict(X_test_r)\n\nreg_metrics = {\n    \"MAE\": mean_absolute_error(y_test_r, y_pred_r),\n    \"RMSE\": mean_squared_error(y_test_r, y_pred_r),\n    \"R2\": r2_score(y_test_r, y_pred_r),\n}\nprint(reg_metrics)\n\n\n{'MAE': 0.21562974252085007, 'RMSE': 0.08044637897153051, 'R2': -0.40250228465286586}\n\n\n\n\nCode\nplt.scatter(y_test_r, y_pred_r, alpha=0.6)\nplt.title(\"Real vs. Predicho (Regresión)\"); plt.xlabel(\"Real\"); plt.ylabel(\"Predicho\"); plt.tight_layout(); plt.show()\n\nres = y_test_r - y_pred_r\nplt.scatter(y_pred_r, res, alpha=0.6); plt.axhline(0, linestyle=\"--\")\nplt.title(\"Residuales vs. Predicción\"); plt.xlabel(\"Predicción\"); plt.ylabel(\"Residual\"); plt.tight_layout(); plt.show()"
  },
  {
    "objectID": "Proyecto_final.html#clustering",
    "href": "Proyecto_final.html#clustering",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "6 5. Clustering",
    "text": "6 5. Clustering\n\n\nCode\nnum_cols_cluster = [\"authorFollowers\", \"account_age_days\", \"mentions_count\", \"hashtags_count\", \"content_length\", \"sentiment_polarity\", \"toxicity_score\"]\ndfc = df[num_cols_cluster].apply(pd.to_numeric, errors=\"coerce\").dropna().reset_index(drop=True)\n\nsil_scores = {}\nbest = {\"k\": None, \"score\": -1, \"labels\": None}\n\nfor k in range(2,7):\n    pipe_km = Pipeline([(\"scaler\", StandardScaler()), (\"km\", KMeans(n_clusters=k, n_init=10, random_state=42))])\n    labels = pipe_km.fit_predict(dfc)\n    sil = silhouette_score(dfc, labels)\n    sil_scores[k] = sil\n    if sil &gt; best[\"score\"]:\n        best = {\"k\": k, \"score\": sil, \"labels\": labels, \"model\": pipe_km}\n\nsil_scores, best[\"k\"], best[\"score\"]\n\n\n({2: 0.9985810886175137,\n  3: 0.026805141053596757,\n  4: 0.3169276806296067,\n  5: 0.15365146886270972,\n  6: 0.05436520939889099},\n 2,\n 0.9985810886175137)\n\n\n\n\nCode\ndfvis = dfc.copy()\ndfvis[\"cluster\"] = best[\"labels\"]\nfor cl in sorted(dfvis[\"cluster\"].unique()):\n    part = dfvis[dfvis[\"cluster\"]==cl]\n    plt.scatter(part[\"sentiment_polarity\"], part[\"toxicity_score\"], alpha=0.6, label=f\"Cluster {cl}\")\nplt.legend(); plt.title(f\"Clusters KMeans (k={best['k']})\"); plt.xlabel(\"sentiment_polarity\"); plt.ylabel(\"toxicity_score\"); plt.tight_layout(); plt.show()\n\n# Relación con target binario (0.5)\ny_bin_all = (dfvis[\"toxicity_score\"] &gt;= 0.5).astype(int)\nct = pd.crosstab(dfvis[\"cluster\"], y_bin_all, normalize=\"index\")*100\nct.round(1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntoxicity_score\n0\n1\n\n\ncluster\n\n\n\n\n\n\n0\n81.9\n18.1\n\n\n1\n100.0\n0.0"
  },
  {
    "objectID": "Proyecto_final.html#conclusiones-y-próximos-pasos",
    "href": "Proyecto_final.html#conclusiones-y-próximos-pasos",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "7 6. Conclusiones y próximos pasos",
    "text": "7 6. Conclusiones y próximos pasos\n\nCalidad de datos y nulos: …\n\nJustificación del umbral para clasificación: …\n\nRendimiento de modelos: …\n\nPatrones en clusters vs clases: …\n\nMejoras propuestas: - Probar Ridge o ElasticNet para regresión. - Ajustar umbrales y class_weight en clasificación; búsqueda de hiperparámetros con GridSearchCV. - Expandir features del texto: ngram_range, min_df, limpieza de URLs, usuarios y emojis. - Evaluar reducción de dimensionalidad para clustering/visualización (PCA/TruncatedSVD)."
  }
]