[
  {
    "objectID": "LABORATORIO_2.html",
    "href": "LABORATORIO_2.html",
    "title": "Laboratorio",
    "section": "",
    "text": "# ====== Importar librerías ======\nimport re\nimport unicodedata\nimport numpy as np\nimport pandas as pd\nimport altair as alt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score,\n    classification_report, ConfusionMatrixDisplay\n)\n\n# NLTK\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download(\"stopwords\", quiet=True)\nstop_es = stopwords.words(\"spanish\")",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#función-de-limpieza",
    "href": "LABORATORIO_2.html#función-de-limpieza",
    "title": "Laboratorio",
    "section": "Función de limpieza",
    "text": "Función de limpieza\n\n# ====== Normalización de texto (conserva 'ñ', quita tildes) ======\n_TILDE_MAP = str.maketrans({\n    \"á\":\"a\",\"é\":\"e\",\"í\":\"i\",\"ó\":\"o\",\"ú\":\"u\",\"Á\":\"a\",\"É\":\"e\",\"Í\":\"i\",\"Ó\":\"o\",\"Ú\":\"u\",\n    \"ü\":\"u\",\"Ü\":\"u\"\n})\n\ndef normalize_text(text: str) -&gt; str:\n    text = str(text)\n    text = text.lower().strip()\n    text = re.sub(r\"https?://\\S+|www\\.\\S+\", \" \", text)  # URLs\n    text = re.sub(r\"@\\w+\", \" \", text)                   # menciones\n    text = re.sub(r\"#\\w+\", \" \", text)                   # hashtags (como texto)\n    text = text.translate(_TILDE_MAP)                   # quitar tildes (NO toca ñ)\n    text = re.sub(r\"[^a-zñ\\s]\", \" \", text)              # solo letras y espacios\n    text = re.sub(r\"\\s+\", \" \", text).strip()            # espacios extra\n    return text\n\n# Asegurar columna 'content'\nif \"content\" not in tweets.columns:\n    raise ValueError(\"No se encontró la columna 'content' en el dataset.\")\n\ntweets[\"clean_text\"] = tweets[\"content\"].fillna(\"\").astype(str).apply(normalize_text)\n\n# Algunas features simples de texto (antes de TF-IDF)\ntweets[\"num_urls\"]      = tweets[\"content\"].fillna(\"\").str.count(r\"https?://|www\\.\")\ntweets[\"num_mentions\"]  = tweets[\"content\"].fillna(\"\").str.count(r\"@\\w+\")\ntweets[\"num_hashtags\"]  = tweets[\"content\"].fillna(\"\").str.count(r\"#\\w+\")\ntweets[\"text_len\"]      = tweets[\"clean_text\"].str.len()\n\ntweets[[\"content\",\"clean_text\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\"text_len\"]].head(5)\n\n\n\n\n\n\n\n\ncontent\nclean_text\nnum_urls\nnum_mentions\nnum_hashtags\ntext_len\n\n\n\n\n0\n@DiegoPonguill10 @DanielNoboaOk @LuisaGonzalez...\njajajaajajajajajajajajjajaajja okkkkkkk\n0\n3\n0\n39\n\n\n1\n@hectorjalonm @DanielNoboaOk @LuisaGonzalezEc ...\nahora vivimos en la miseria antes fuimos el me...\n0\n3\n0\n71\n\n\n2\n@Gregori58965636 @yesendiaz @DanielNoboaOk Otr...\notro troll basura\n0\n3\n0\n17\n\n\n3\n@jdiegol2010 @DanielNoboaOk https://t.co/CsLWQ...\n\n1\n2\n0\n0\n\n\n4\n@JRamirez2O24 @DanielNoboaOk El tema es respet...\nel tema es respetar a quien eligio el pueblo o no\n0\n2\n0\n49",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#palabras-que-demuestran-apoyo-o-disgusto",
    "href": "LABORATORIO_2.html#palabras-que-demuestran-apoyo-o-disgusto",
    "title": "Laboratorio",
    "section": "Palabras que demuestran apoyo o disgusto",
    "text": "Palabras que demuestran apoyo o disgusto\n\nlex_neg = {\n    \"asco\",\"basura\",\"corrupto\",\"estupido\",\"idiota\",\"ladron\",\"mentiroso\",\"odiar\",\"odio\",\n    \"imbecil\",\"tonto\",\"vomito\",\"repugnante\",\"asqueroso\",\"miserable\"\n}\nlex_pos = {\n    \"apoyo\",\"gracias\",\"excelente\",\"felicitaciones\",\"bien\",\"bravo\",\"genial\",\"mejor\",\n    \"aplaudo\",\"orgullo\",\"feliz\",\"contento\",\"admiro\",\"fuerza\",\"vamos\"\n}\n\ndef count_lexicon_hits(text: str, lexicon: set) -&gt; int:\n    if not text:\n        return 0\n    tokens = text.split()\n    return sum(1 for t in tokens if t in lexicon)\n\ntweets[\"neg_count\"] = tweets[\"clean_text\"].apply(lambda t: count_lexicon_hits(t, lex_neg))\ntweets[\"pos_count\"] = tweets[\"clean_text\"].apply(lambda t: count_lexicon_hits(t, lex_pos))\n\ntweets[[\"clean_text\",\"neg_count\",\"pos_count\"]].head(5)\n\n\n\n\n\n\n\n\nclean_text\nneg_count\npos_count\n\n\n\n\n0\njajajaajajajajajajajajjajaajja okkkkkkk\n0\n0\n\n\n1\nahora vivimos en la miseria antes fuimos el me...\n0\n1\n\n\n2\notro troll basura\n1\n0\n\n\n3\n\n0\n0\n\n\n4\nel tema es respetar a quien eligio el pueblo o no\n0\n0",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#creación-de-etiquetas-con-labelencoder",
    "href": "LABORATORIO_2.html#creación-de-etiquetas-con-labelencoder",
    "title": "Laboratorio",
    "section": "Creación de etiquetas con LabelEncoder",
    "text": "Creación de etiquetas con LabelEncoder\n\n# Columnas esperadas (si no están, se crean como 0 para evitar errores)\ncols_flags = [\"isReply\", \"authorVerified\", \"has_profile_picture\"]\nfor c in cols_flags:\n    if c not in tweets.columns:\n        tweets[c] = 0\n\n# Crear nuevas columnas *_encoded usando LabelEncoder (manteniendo el estilo previo)\nfor c in cols_flags:\n    le = LabelEncoder()\n    # Convertimos a string por robustez ante valores no booleanos\n    tweets[f\"{c}_encoded\"] = le.fit_transform(tweets[c].astype(str))\n\ntweets[[f\"{c}_encoded\" for c in cols_flags]].head(5)\n\n\n\n\n\n\n\n\nisReply_encoded\nauthorVerified_encoded\nhas_profile_picture_encoded\n\n\n\n\n0\n0\n0\n1\n\n\n1\n0\n0\n1\n\n\n2\n0\n0\n1\n\n\n3\n0\n0\n1\n\n\n4\n0\n0\n1",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#construcción-de-variable-target-basada-en-caractisticas-de-usuarios",
    "href": "LABORATORIO_2.html#construcción-de-variable-target-basada-en-caractisticas-de-usuarios",
    "title": "Laboratorio",
    "section": "Construcción de variable target basada en caractisticas de usuarios",
    "text": "Construcción de variable target basada en caractisticas de usuarios\n\n# Asegurar columnas numéricas (si no existen, se crean con 0)\nnum_needed = [\"account_age_days\", \"time_response\"]\nfor c in num_needed:\n    if c not in tweets.columns:\n        tweets[c] = 0\n\n# Cast numérico seguro\nfor c in [\"account_age_days\",\"time_response\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\n          \"text_len\",\"neg_count\",\"pos_count\",\n          \"isReply_encoded\",\"authorVerified_encoded\",\"has_profile_picture_encoded\"]:\n    tweets[c] = pd.to_numeric(tweets[c], errors=\"coerce\").fillna(0)\n\n# Reglas -&gt; puntos\nscore = np.zeros(len(tweets), dtype=int)\n\nscore += (tweets[\"account_age_days\"] &lt; 30).astype(int)                   # cuenta reciente\nscore += (tweets[\"time_response\"] &lt; 30).astype(int)                      # respuesta muy rápida (ajusta a tu caso)\nscore += (tweets[\"authorVerified_encoded\"] == 0).astype(int)             # no verificada\nscore += (tweets[\"has_profile_picture_encoded\"] == 0).astype(int)        # sin foto\nscore += ((tweets[\"num_urls\"] + tweets[\"num_mentions\"] + tweets[\"num_hashtags\"]) &gt;= 3).astype(int)  # mucho \"ruido\"\nscore += ((tweets[\"neg_count\"] &gt; tweets[\"pos_count\"]) & (tweets[\"neg_count\"] &gt;= 2)).astype(int)     # negatividad marcada\n\n# Umbral: 3 señales o más =&gt; bot\ntweets[\"bots\"] = (score &gt;= 3).astype(int)\n\nprint(\"Distribución de 'bots':\")\nprint(tweets[\"bots\"].value_counts(dropna=False))\n\nDistribución de 'bots':\nbots\n0    147332\n1     11541\nName: count, dtype: int64",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#vectorización-de-texto",
    "href": "LABORATORIO_2.html#vectorización-de-texto",
    "title": "Laboratorio",
    "section": "Vectorización de texto",
    "text": "Vectorización de texto\n\n# TF-IDF sobre 'clean_text' (español)\ntfidf = TfidfVectorizer(stop_words=stop_es, min_df=5)  # sube/baja min_df según dataset\n\nX_text = tfidf.fit_transform(tweets[\"clean_text\"])\nvocab   = tfidf.get_feature_names_out()\nprint(\"Matriz TF-IDF:\", X_text.shape)\nprint(\"Ejemplo de vocab:\", vocab[:20])\n\nMatriz TF-IDF: (158873, 16345)\nEjemplo de vocab: ['aa' 'aaa' 'aaaa' 'aaaah' 'ab' 'abad' 'abajo' 'abandona' 'abandonada'\n 'abandonadas' 'abandonado' 'abandonados' 'abandonar' 'abandonaron'\n 'abandone' 'abandono' 'abatidos' 'abdala' 'abel' 'aberracion']",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#one-hot-encoder-para-variables-categoricas-método-de-autodetección",
    "href": "LABORATORIO_2.html#one-hot-encoder-para-variables-categoricas-método-de-autodetección",
    "title": "Laboratorio",
    "section": "One hot encoder para variables categoricas (método de autodetección)",
    "text": "One hot encoder para variables categoricas (método de autodetección)\n\n# Detectar automáticamente columnas object para One-Hot (excluyendo 'content'/'clean_text')\nobj_cols = [c for c in tweets.select_dtypes(include=[\"object\"]).columns\n            if c not in {\"content\",\"clean_text\"}]\n\nobj_cols[:10]\n\n['tweetUrl',\n 'replyTo',\n 'createdAt',\n 'authorName',\n 'authorUsername',\n 'authorProfilePic',\n 'authorJoinDate',\n 'source',\n 'hashtags',\n 'mentions']",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#ensamble-númericas-label-ecoder-categóticas-one-hot-encoder-text-columntransformer",
    "href": "LABORATORIO_2.html#ensamble-númericas-label-ecoder-categóticas-one-hot-encoder-text-columntransformer",
    "title": "Laboratorio",
    "section": "Ensamble: númericas (Label Ecoder) + categóticas (One-hot-encoder) + text (columntransformer)",
    "text": "Ensamble: númericas (Label Ecoder) + categóticas (One-hot-encoder) + text (columntransformer)\n\n# Numéricas explícitas (puedes añadir/quitar)\nnum_cols = [\n    \"account_age_days\",\"time_response\",\"num_urls\",\"num_mentions\",\"num_hashtags\",\"text_len\",\n    \"neg_count\",\"pos_count\",\n    # Flags codificados por LabelEncoder (ya son numéricos)\n    \"isReply_encoded\",\"authorVerified_encoded\",\"has_profile_picture_encoded\"\n]\n\n# Algunas podrían no existir (si el dataset original varía)\nnum_cols = [c for c in num_cols if c in tweets.columns]\n\n# Preprocesador\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"num\",  Pipeline([(\"scaler\", StandardScaler())]), num_cols),\n        (\"cat\",  OneHotEncoder(handle_unknown=\"ignore\", sparse_output=True), obj_cols),\n        (\"text\", tfidf, \"clean_text\"),\n    ],\n    remainder=\"drop\",\n    sparse_threshold=1.0  # mantenemos salida esparza por el bloque texto\n)\n\n# Modelo\nclf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")  # balanced por si hay desbalance\npipe = Pipeline([\n    (\"prep\", preprocessor),\n    (\"clf\",  clf)\n])\n\n# X e y finales\nX = tweets[[\"clean_text\"] + num_cols + obj_cols]  # el CT tomará lo que necesita\ny = tweets[\"bots\"].astype(int)\n\nprint(\"Clases en y:\", dict(y.value_counts()))\n\nClases en y: {0: np.int64(147332), 1: np.int64(11541)}",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#split-división-entrenamiento-y-evaluación",
    "href": "LABORATORIO_2.html#split-división-entrenamiento-y-evaluación",
    "title": "Laboratorio",
    "section": "Split (división), entrenamiento y evaluación",
    "text": "Split (división), entrenamiento y evaluación\nAprende de los tweets (vocabulario) y del ser caso elimina las stop-words\n\n# Si hay 1 sola clase, relajamos umbral de bots para forzar 2 clases (safeguard)\nif y.nunique() &lt; 2:\n    print(\"⚠️ 'bots' tiene una sola clase con el umbral actual. Bajando el umbral a &gt;=2 señales.\")\n    tweets[\"bots\"] = (score &gt;= 2).astype(int)\n    y = tweets[\"bots\"].astype(int)\n    print(\"Nuevas clases en y:\", dict(y.value_counts()))\n\n# Estratificar solo si hay 2 clases\nstratify_opt = y if y.nunique() &gt; 1 else None\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=stratify_opt\n)\n\npipe.fit(X_train, y_train)\ny_pred = pipe.predict(X_test)\n\nacc  = accuracy_score(y_test, y_pred)\nprec = precision_score(y_test, y_pred, zero_division=0)\nrec  = recall_score(y_test, y_pred, zero_division=0)\nf1   = f1_score(y_test, y_pred, zero_division=0)\n\nprint(f\"accuracy:  {acc:.3f}\")\nprint(f\"precision: {prec:.3f}\")\nprint(f\"recall:    {rec:.3f}\")\nprint(f\"f1:        {f1:.3f}\")\n\nprint(\"\\nClassification report:\")\nprint(classification_report(y_test, y_pred, zero_division=0))\n\naccuracy:  0.952\nprecision: 0.636\nrecall:    0.788\nf1:        0.704\n\nClassification report:\n              precision    recall  f1-score   support\n\n           0       0.98      0.96      0.97     29467\n           1       0.64      0.79      0.70      2308\n\n    accuracy                           0.95     31775\n   macro avg       0.81      0.88      0.84     31775\nweighted avg       0.96      0.95      0.95     31775",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#matriz-de-confusión",
    "href": "LABORATORIO_2.html#matriz-de-confusión",
    "title": "Laboratorio",
    "section": "Matriz de confusión",
    "text": "Matriz de confusión\n\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "LABORATORIO_2.html#inspección-palabras-más-comunes-tf-idf",
    "href": "LABORATORIO_2.html#inspección-palabras-más-comunes-tf-idf",
    "title": "Laboratorio",
    "section": "Inspección: palabras más comunes (TF-IDF)",
    "text": "Inspección: palabras más comunes (TF-IDF)\n\n# Top términos por TF-IDF medio (en el train)\nfrom scipy.sparse import issparse\n\nX_train_text = pipe.named_steps[\"prep\"].named_transformers_[\"text\"].transform(X_train[\"clean_text\"])\nidf_vocab    = pipe.named_steps[\"prep\"].named_transformers_[\"text\"].get_feature_names_out()\n\n# Promedio por columna\nif issparse(X_train_text):\n    col_means = np.array(X_train_text.mean(axis=0)).ravel()\nelse:\n    col_means = X_train_text.mean(axis=0)\n\ntop_idx = np.argsort(col_means)[::-1][:20]\ntop_terms = [(idf_vocab[i], float(col_means[i])) for i in top_idx]\npd.DataFrame(top_terms, columns=[\"term\",\"mean_tfidf\"])\n\n\n\n\n\n\n\n\nterm\nmean_tfidf\n\n\n\n\n0\nluisa\n0.018745\n\n\n1\nsi\n0.015491\n\n\n2\nmas\n0.014759\n\n\n3\npresidente\n0.014515\n\n\n4\nnoboa\n0.014076\n\n\n5\necuador\n0.011523\n\n\n6\npais\n0.010178\n\n\n7\npresidenta\n0.009667\n\n\n8\nsolo\n0.008450\n\n\n9\nrana\n0.007805\n\n\n10\nrene\n0.007487\n\n\n11\nnunca\n0.006732\n\n\n12\nasi\n0.006544\n\n\n13\nvamos\n0.006476\n\n\n14\nbien\n0.006353\n\n\n15\nser\n0.006154\n\n\n16\npueblo\n0.005984\n\n\n17\ncorrea\n0.005610\n\n\n18\nmejor\n0.005541\n\n\n19\nva\n0.005462",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Laboratorio"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratorio 2 - Módulo de aprendizaje de máquina",
    "section": "",
    "text": "Laboratorio 2\nMódulo de aprendizaje de máquina Yachaytech 2025\nRealizado por: Jorge Delgado",
    "crumbs": [
      "Inicio"
    ]
  }
]