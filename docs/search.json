[
  {
    "objectID": "Proyecto_final.html",
    "href": "Proyecto_final.html",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport re, ast\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize # tokenizacion\nfrom nltk import pos_tag #lematizacion\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom wordcloud import WordCloud\nfrom collections import Counter\n\nnltk.download(\"punkt\", quiet=True)\nnltk.download(\"stopwords\", quiet=True)\nstop_es = stopwords.words(\"spanish\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n    classification_report, ConfusionMatrixDisplay,\n    mean_absolute_error, mean_squared_error, r2_score,\n    silhouette_score\n)\n\nfrom sklearn.cluster import KMeans\n\n# Ruta al CSV (deja el archivo en la misma carpeta que este .qmd)\ndf = pd.read_csv(\"data/1500_tweets_con_toxicity.csv\", encoding=\"utf-8\")\ndf.head()\n\n\n\n\n\n\n\n\n\ntweetId\ntweetUrl\ncontent\nisReply\nreplyTo\ncreatedAt\nauthorId\nauthorName\nauthorUsername\nauthorVerified\n...\ninReplyToId\nDate\ntime_response\naccount_age_days\nmentions_count\nhashtags_count\ncontent_length\nhas_profile_picture\nsentiment_polarity\ntoxicity_score\n\n\n\n\n0\n1878630970745900800\nhttps://x.com/Pableins15/status/18786309707459...\n@DanielNoboaOk @DiegoBorjaPC Lávate el hocico ...\nTrue\nDanielNoboaOk\n2025-01-13 02:31:00\n176948611\nPablo Balarezo\nPableins15\nFalse\n...\n1878539079249547520\n2025-01-12 20:26:32\n364.466667\n5261\n2\n0\n309\nFalse\n0.0\n0.543256\n\n\n1\n1904041877503984128\nhttps://x.com/solma1201/status/190404187750398...\n@DanielNoboaOk De esa arrastrada no te levanta...\nTrue\nDanielNoboaOk\n2025-03-24 05:25:00\n1368663286582030336\nSolma1201\nsolma1201\nFalse\n...\n1904003201143115776\n2025-03-24 02:51:52\n153.133333\n1399\n1\n0\n70\nTrue\n0.0\n0.426917\n\n\n2\n1877463444649046016\nhttps://x.com/Mediterran67794/status/187746344...\n@LuisaGonzalezEc @RC5Oficial Protegiendo a los...\nTrue\nLuisaGonzalezEc\n2025-01-09 21:12:00\n1851005619106451712\nMédico Escritor Filósofo Hermeneútico\nMediterran67794\nFalse\n...\n1877158437236228352\n2025-01-09 01:00:22\n1211.633333\n68\n2\n0\n122\nTrue\n0.0\n0.555970\n\n\n3\n1881356046108885248\nhttps://x.com/ardededa/status/1881356046108885494\n@DanielNoboaOk #NoboaPresidente. Todo 7!\nTrue\nDanielNoboaOk\n2025-01-20 15:00:00\n315799544\nDenise\nardededa\nFalse\n...\n1881165128185560832\n2025-01-20 02:21:31\n758.483333\n4955\n1\n0\n41\nTrue\n0.0\n0.046615\n\n\n4\n1888331962063978752\nhttps://x.com/LMarquinezm/status/1888331962063...\n@slider1908 @LuisaGonzalezEc @DianaAtamaint @c...\nTrue\nslider1908\n2025-02-08 20:59:00\n1551883554\nLuis Marquínez\nLMarquinezm\nFalse\n...\n1888256000085397504\n2025-02-08 14:59:07\n359.883333\n4208\n5\n0\n101\nTrue\n0.0\n0.846027\n\n\n\n\n5 rows × 27 columns",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "Proyecto_final.html#preparación",
    "href": "Proyecto_final.html#preparación",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "",
    "text": "Code\nimport pandas as pd\nimport numpy as np\nimport re, ast\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize # tokenizacion\nfrom nltk import pos_tag #lematizacion\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom wordcloud import WordCloud\nfrom collections import Counter\n\nnltk.download(\"punkt\", quiet=True)\nnltk.download(\"stopwords\", quiet=True)\nstop_es = stopwords.words(\"spanish\")\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression, LinearRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n    classification_report, ConfusionMatrixDisplay,\n    mean_absolute_error, mean_squared_error, r2_score,\n    silhouette_score\n)\n\nfrom sklearn.cluster import KMeans\n\n# Ruta al CSV (deja el archivo en la misma carpeta que este .qmd)\ndf = pd.read_csv(\"data/1500_tweets_con_toxicity.csv\", encoding=\"utf-8\")\ndf.head()\n\n\n\n\n\n\n\n\n\ntweetId\ntweetUrl\ncontent\nisReply\nreplyTo\ncreatedAt\nauthorId\nauthorName\nauthorUsername\nauthorVerified\n...\ninReplyToId\nDate\ntime_response\naccount_age_days\nmentions_count\nhashtags_count\ncontent_length\nhas_profile_picture\nsentiment_polarity\ntoxicity_score\n\n\n\n\n0\n1878630970745900800\nhttps://x.com/Pableins15/status/18786309707459...\n@DanielNoboaOk @DiegoBorjaPC Lávate el hocico ...\nTrue\nDanielNoboaOk\n2025-01-13 02:31:00\n176948611\nPablo Balarezo\nPableins15\nFalse\n...\n1878539079249547520\n2025-01-12 20:26:32\n364.466667\n5261\n2\n0\n309\nFalse\n0.0\n0.543256\n\n\n1\n1904041877503984128\nhttps://x.com/solma1201/status/190404187750398...\n@DanielNoboaOk De esa arrastrada no te levanta...\nTrue\nDanielNoboaOk\n2025-03-24 05:25:00\n1368663286582030336\nSolma1201\nsolma1201\nFalse\n...\n1904003201143115776\n2025-03-24 02:51:52\n153.133333\n1399\n1\n0\n70\nTrue\n0.0\n0.426917\n\n\n2\n1877463444649046016\nhttps://x.com/Mediterran67794/status/187746344...\n@LuisaGonzalezEc @RC5Oficial Protegiendo a los...\nTrue\nLuisaGonzalezEc\n2025-01-09 21:12:00\n1851005619106451712\nMédico Escritor Filósofo Hermeneútico\nMediterran67794\nFalse\n...\n1877158437236228352\n2025-01-09 01:00:22\n1211.633333\n68\n2\n0\n122\nTrue\n0.0\n0.555970\n\n\n3\n1881356046108885248\nhttps://x.com/ardededa/status/1881356046108885494\n@DanielNoboaOk #NoboaPresidente. Todo 7!\nTrue\nDanielNoboaOk\n2025-01-20 15:00:00\n315799544\nDenise\nardededa\nFalse\n...\n1881165128185560832\n2025-01-20 02:21:31\n758.483333\n4955\n1\n0\n41\nTrue\n0.0\n0.046615\n\n\n4\n1888331962063978752\nhttps://x.com/LMarquinezm/status/1888331962063...\n@slider1908 @LuisaGonzalezEc @DianaAtamaint @c...\nTrue\nslider1908\n2025-02-08 20:59:00\n1551883554\nLuis Marquínez\nLMarquinezm\nFalse\n...\n1888256000085397504\n2025-02-08 14:59:07\n359.883333\n4208\n5\n0\n101\nTrue\n0.0\n0.846027\n\n\n\n\n5 rows × 27 columns",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "Proyecto_final.html#eda",
    "href": "Proyecto_final.html#eda",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "2 1. EDA",
    "text": "2 1. EDA\n\n\nCode\ndf.info()\n\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 1500 entries, 0 to 1499\nData columns (total 27 columns):\n #   Column               Non-Null Count  Dtype  \n---  ------               --------------  -----  \n 0   tweetId              1500 non-null   int64  \n 1   tweetUrl             1500 non-null   object \n 2   content              1500 non-null   object \n 3   isReply              1500 non-null   bool   \n 4   replyTo              1490 non-null   object \n 5   createdAt            1500 non-null   object \n 6   authorId             1500 non-null   int64  \n 7   authorName           1500 non-null   object \n 8   authorUsername       1500 non-null   object \n 9   authorVerified       1500 non-null   bool   \n 10  authorFollowers      1500 non-null   int64  \n 11  authorProfilePic     1500 non-null   object \n 12  authorJoinDate       1500 non-null   object \n 13  source               1500 non-null   object \n 14  hashtags             121 non-null    object \n 15  mentions             1499 non-null   object \n 16  conversationId       1500 non-null   int64  \n 17  inReplyToId          1500 non-null   int64  \n 18  Date                 1500 non-null   object \n 19  time_response        1500 non-null   float64\n 20  account_age_days     1500 non-null   int64  \n 21  mentions_count       1500 non-null   int64  \n 22  hashtags_count       1500 non-null   int64  \n 23  content_length       1500 non-null   int64  \n 24  has_profile_picture  1500 non-null   bool   \n 25  sentiment_polarity   1500 non-null   float64\n 26  toxicity_score       1347 non-null   float64\ndtypes: bool(3), float64(3), int64(9), object(12)\nmemory usage: 285.8+ KB\n\n\n\n\nCode\n# Detectar tipos de columnas\nnum_vars = df.select_dtypes(include=['number']).columns\ncat_vars = df.select_dtypes(include=['object', 'category']).columns\ntext_vars = [col for col in df.columns if df[col].dtype == 'object' and df[col].str.len().mean() &gt; 30]\n\n# Mostrar resultados\nprint(\"Tipos de variables en el DataFrame:\\n\")\nprint(f\"Variables numéricas ({len(num_vars)}): {list(num_vars)}\")\nprint(f\"Variables categóricas ({len(cat_vars)}): {list(cat_vars)}\")\nprint(f\"Variables de texto ({len(text_vars)}): {list(text_vars)}\")\n\n# Resumen tabular:\nresumen = pd.DataFrame({\n    'Tipo': ['Numéricas', 'Categóricas', 'Texto'],\n    'Cantidad': [len(num_vars), len(cat_vars), len(text_vars)]\n})\n\ndisplay(resumen)\n\n\nTipos de variables en el DataFrame:\n\nVariables numéricas (12): ['tweetId', 'authorId', 'authorFollowers', 'conversationId', 'inReplyToId', 'time_response', 'account_age_days', 'mentions_count', 'hashtags_count', 'content_length', 'sentiment_polarity', 'toxicity_score']\nVariables categóricas (12): ['tweetUrl', 'content', 'replyTo', 'createdAt', 'authorName', 'authorUsername', 'authorProfilePic', 'authorJoinDate', 'source', 'hashtags', 'mentions', 'Date']\nVariables de texto (3): ['tweetUrl', 'content', 'authorProfilePic']\n\n\n\n\n\n\n\n\n\nTipo\nCantidad\n\n\n\n\n0\nNuméricas\n12\n\n\n1\nCategóricas\n12\n\n\n2\nTexto\n3\n\n\n\n\n\n\n\n\n\nCode\n# Resumen numérico\ndf.describe(include=\"number\").T\n\n\n\n\n\n\n\n\n\ncount\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\n\n\ntweetId\n1500.0\n1.893421e+18\n1.166584e+16\n1.876011e+18\n1.883283e+18\n1.887876e+18\n1.904588e+18\n1.922145e+18\n\n\nauthorId\n1500.0\n9.838015e+17\n7.900284e+17\n1.159021e+06\n9.690383e+08\n1.318014e+18\n1.710233e+18\n1.908229e+18\n\n\nauthorFollowers\n1500.0\n3.625721e+03\n1.184447e+05\n0.000000e+00\n7.000000e+00\n4.300000e+01\n1.992500e+02\n4.577730e+06\n\n\nconversationId\n1500.0\n1.893127e+18\n1.161854e+16\n1.876001e+18\n1.883238e+18\n1.887344e+18\n1.904198e+18\n1.910014e+18\n\n\ninReplyToId\n1500.0\n1.893147e+18\n1.162094e+16\n1.876001e+18\n1.883238e+18\n1.887355e+18\n1.904234e+18\n1.910015e+18\n\n\ntime_response\n1500.0\n1.170038e+03\n3.273930e+03\n1.333333e-01\n1.363000e+02\n5.156250e+02\n1.265717e+03\n6.356900e+04\n\n\naccount_age_days\n1500.0\n2.271134e+03\n1.984157e+03\n-9.000000e+01\n4.557500e+02\n1.538000e+03\n4.420750e+03\n6.506000e+03\n\n\nmentions_count\n1500.0\n1.723333e+00\n9.462483e-01\n0.000000e+00\n1.000000e+00\n2.000000e+00\n2.000000e+00\n1.000000e+01\n\n\nhashtags_count\n1500.0\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n\n\ncontent_length\n1500.0\n1.165280e+02\n7.749371e+01\n1.700000e+01\n5.700000e+01\n9.600000e+01\n1.500000e+02\n6.840000e+02\n\n\nsentiment_polarity\n1500.0\n-7.906765e-03\n1.197964e-01\n-1.000000e+00\n0.000000e+00\n0.000000e+00\n0.000000e+00\n1.000000e+00\n\n\ntoxicity_score\n1347.0\n2.538788e-01\n2.439420e-01\n1.939886e-03\n2.844395e-02\n1.883923e-01\n4.269174e-01\n9.391453e-01\n\n\n\n\n\n\n\n\n\nCode\nnum_df = df.select_dtypes(include=['number'])\n# Distribución (histogramas)\nprint(\"\\n Distribuciones de variables numéricas:\")\nnum_df.hist(bins=20, figsize=(12, 8), edgecolor='black')\nplt.suptitle(\"Distribución de variables numéricas\", fontsize=14)\nplt.tight_layout()\nplt.show()\n\n\n\n Distribuciones de variables numéricas:\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Resumen categórico\ndf.select_dtypes(exclude=\"number\").nunique().sort_values(ascending=False).head(20)\n\n\ntweetUrl               1500\ncontent                1491\ncreatedAt              1460\nauthorUsername         1386\nauthorJoinDate         1386\nauthorName             1375\nauthorProfilePic       1322\nDate                    382\nmentions                340\nreplyTo                 240\nhashtags                 83\nhas_profile_picture       2\nisReply                   1\nsource                    1\nauthorVerified            1\ndtype: int64\n\n\n\n\nCode\n# Nulos y duplicados\nmissing = df.isna().sum().sort_values(ascending=False).to_frame(\"n_missing\")\nmissing[\"pct\"] = (df.isna().mean()*100).sort_values(ascending=False)\nmissing.head(10)\n\n\n\n\n\n\n\n\n\nn_missing\npct\n\n\n\n\nhashtags\n1379\n91.933333\n\n\ntoxicity_score\n153\n10.200000\n\n\nreplyTo\n10\n0.666667\n\n\nmentions\n1\n0.066667\n\n\ncontent\n0\n0.000000\n\n\ncreatedAt\n0\n0.000000\n\n\nauthorId\n0\n0.000000\n\n\nauthorName\n0\n0.000000\n\n\nisReply\n0\n0.000000\n\n\ntweetUrl\n0\n0.000000\n\n\n\n\n\n\n\n\n\nCode\n# Distribución toxicity_score\ndf[\"toxicity_score\"] = pd.to_numeric(df[\"toxicity_score\"], errors=\"coerce\")\ndf[\"toxicity_score\"].dropna().hist(bins=30)\nplt.title(\"Distribución de toxicity_score\")\nplt.xlabel(\"toxicity_score\"); plt.ylabel(\"Frecuencia\"); plt.show()\n\ndf[\"toxicity_score\"].describe(percentiles=[0.1,0.25,0.5,0.75,0.9,0.95])\n\n\n\n\n\n\n\n\n\ncount    1347.000000\nmean        0.253879\nstd         0.243942\nmin         0.001940\n10%         0.006333\n25%         0.028444\n50%         0.188392\n75%         0.426917\n90%         0.602753\n95%         0.749544\nmax         0.939145\nName: toxicity_score, dtype: float64\n\n\n\n\nCode\nplt.figure(figsize=(10,4))\nplt.subplot(1,2,1)\nsns.histplot(df['toxicity_score'], bins=30, kde=True, color='steelblue')\nplt.title('Distribución de toxicity_score')\nplt.xlabel('toxicity_score')\nplt.ylabel('Frecuencia')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Boxplots de numéricas clave\nnum_cols = [\"authorFollowers\", \"time_response\", \"account_age_days\", \"mentions_count\", \"hashtags_count\", \"content_length\", \"sentiment_polarity\"]\npresent = [c for c in num_cols if c in df.columns]\ndf[present].boxplot(rot=45); plt.title(\"Boxplots numéricos\"); plt.tight_layout(); plt.show()\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Top hashtags y menciones\ndef parse_list_like(x):\n    if pd.isna(x): return []\n    s = str(x).strip()\n    try:\n        obj = ast.literal_eval(s)\n        if isinstance(obj, list):\n            return [str(t).strip().lower() for t in obj if str(t).strip()]\n    except Exception:\n        pass\n    s = re.sub(r\"[\\[\\]{}()'\\\"#]\", \" \", s)\n    tokens = re.split(r\"[,\\s]+\", s)\n    return [t.strip().lower() for t in tokens if t.strip()]\n\nfor col, title in [(\"hashtags\",\"Top hashtags\"), (\"mentions\",\"Top menciones\")]:\n    if col in df.columns:\n        items = []\n        for v in df[col]:\n            items.extend(parse_list_like(v))\n        if items:\n            top = pd.Series(items).value_counts().head(20)\n            top.sort_values(ascending=True).plot(kind=\"barh\"); plt.title(title); plt.tight_layout(); plt.show()\n            display(top.to_frame(\"count\"))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncount\n\n\n\n\nluisapresidenta\n38\n\n\nluisaporlavida\n19\n\n\nrevivirecuador\n16\n\n\nnoboanuncamás\n10\n\n\nluisaeslaesperanza\n7\n\n\nluisagonzálezpresidenta\n5\n\n\ngdorc5\n4\n\n\nluisaaprendearespetar\n4\n\n\nnuncamas\n4\n\n\nelecciones2025ec\n4\n\n\ncambioseguro\n4\n\n\ndebatepresidencial\n4\n\n\nnoboanoseraspresidente\n3\n\n\nnoboaescorrupción\n3\n\n\nranarené\n3\n\n\nluisadesdolariza\n3\n\n\necuadordebate\n2\n\n\necuadorconnoboa\n2\n\n\nrcnuncamas\n2\n\n\ncorreismo\n2\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncount\n\n\n\n\n@luisagonzalezec\n975\n\n\n@danielnoboaok\n561\n\n\n@rc5oficial\n333\n\n\n@diegoborjapc\n54\n\n\n@ffaaecuador\n33\n\n\n@mashirafael\n30\n\n\n@cnegobec\n28\n\n\n@dianaatamaint\n26\n\n\n@cnnee\n15\n\n\n@soyfdelrincon\n14\n\n\n@ecuarauz\n13\n\n\n@aquilesalvarez\n12\n\n\n@mariacorinaya\n11\n\n\n@soybelenix\n10\n\n\n@aguschmer\n6\n\n\n@asambleaecuador\n6\n\n\n@chrisviteri\n5\n\n\n@janethinostroza\n5\n\n\n@bancomundial\n5\n\n\n@ricardopatinoec\n5\n\n\n\n\n\n\n\n\n\nCode\n# Conteo de Variables categóricas\n\ncat_cols = df.select_dtypes(include=['object', 'category']).columns\n\nif len(cat_cols) &gt; 0:\n    for col in cat_cols[:5]:  # graficar hasta 5 variables categóricas\n        # Contar categorías y tomar solo las 10 principales\n        top_cats = df[col].value_counts().head(10)\n\n        plt.figure(figsize=(8, 4))\n        sns.barplot(y=top_cats.index, x=top_cats.values, palette='viridis')\n        plt.title(f\"Top 10 categorías más frecuentes en: {col}\")\n        plt.xlabel(\"Frecuencia\")\n        plt.ylabel(col)\n        plt.tight_layout()\n        plt.show()\nelse:\n    print(\"No hay variables categóricas para graficar.\\n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCode\n# Detectar variable de texto\ntext_cols = [col for col in df.columns if df[col].dtype == 'object' and df[col].str.len().mean() &gt; 30]\n\nif len(text_cols) &gt; 0:\n    col_texto = text_cols[1]  # usa la segunda columna tipo texto\n    texto = \" \".join(df[col_texto].dropna().astype(str))\n\n    # --- Generar nube de palabras ---\n    plt.figure(figsize=(10,6))\n    wc = WordCloud(width=800, height=400, background_color='white', colormap='viridis', max_words=100).generate(texto)\n    plt.imshow(wc, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.title(f\"Nube de palabras - {col_texto}\")\n    plt.show()\n\n    # --- Calcular las 10 palabras más frecuentes ---\n    palabras = texto.split()\n    frec = Counter(palabras)\n    comunes = pd.DataFrame(frec.most_common(10), columns=['Palabra', 'Frecuencia'])\n\n    # --- Gráfico Top 10 ---\n    plt.figure(figsize=(8,4))\n    sns.barplot(data=comunes, x='Frecuencia', y='Palabra', palette='mako')\n    plt.title(f\"Top 10 palabras más representativas - {col_texto}\")\n    plt.tight_layout()\n    plt.show()\n\n    # --- Mostrar tabla ---\n    display(comunes)\nelse:\n    print(\"No se detectó ninguna columna de texto para generar la nube de palabras.\\n\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPalabra\nFrecuencia\n\n\n\n\n0\n@LuisaGonzalezEc\n969\n\n\n1\nde\n771\n\n\n2\nque\n659\n\n\n3\n@DanielNoboaOk\n559\n\n\n4\nla\n534\n\n\n5\na\n511\n\n\n6\ny\n473\n\n\n7\nel\n428\n\n\n8\nno\n348\n\n\n9\n@RC5Oficial\n333\n\n\n\n\n\n\n\n\n\nCode\n#Correlación de las variables numéricas\nnumeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\nif len(numeric_cols) &gt; 1:\n    # Matriz de correlación\n    correlation_matrix = df[numeric_cols].corr()\n    \n    plt.figure(figsize=(10, 8))\n    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n                square=True, fmt='.2f')\n    plt.title('Matriz de Correlación de Variables Numéricas')\n    plt.tight_layout()\n    plt.show()\n    \n    # Top correlaciones con toxicidad\n    if 'toxicity_score' in numeric_cols:\n        toxicity_corr = correlation_matrix['toxicity_score'].abs().sort_values(ascending=False)\n        print(f\"=== CORRELACIONES CON {'toxicity_score'.upper()} ===\")\n        print(toxicity_corr.head(10))\n\n\n\n\n\n\n\n\n\n=== CORRELACIONES CON TOXICITY_SCORE ===\ntoxicity_score        1.000000\ncontent_length        0.178799\nsentiment_polarity    0.165296\nconversationId        0.110512\ninReplyToId           0.110335\ntweetId               0.105659\ntime_response         0.059059\nauthorId              0.037683\naccount_age_days      0.032867\nmentions_count        0.026670\nName: toxicity_score, dtype: float64\n\n\nHallazgos clave (EDA):\n\n\nCode\nprint(\"DISTRIBUCIÓN DE LOS DATOS:\")\nprint(f\"- Mi Set de datos tiene {df.shape[0]} observaciones y {df.shape[1]} variables\")\nprint(f\"- Variables numéricas son: {len(numeric_cols)}\")\nprint(f\"- Variables categóricas son: {len(cat_cols)}\")\n\nprint(f\"VARIABLE OBJETIVO (Score de TOXICIDAD):\")\ntoxicity_mean = df['toxicity_score'].mean()\ntoxicity_std = df['toxicity_score'].std()\nprint(f\"- Media de toxicidad: {toxicity_mean:.4f}\")\nprint(f\"- Desviación estándar: {toxicity_std:.4f}\")\nprint(f\"- La mayoría de tweets tienen baja toxicidad pues son menores a 0.5, la toxicidad media es: {toxicity_mean:.4f}\")\n\nprint(f\"Distribución de `toxicity_score` con mediana, cuartiles y % de valores altos.\")\nprint(f\"Campos con nulos relevantes (p.ej. `toxicity_score` y `hashtags`).\")\nprint(f\"Concentración de polaridad y relación preliminar con la toxicidad.\")\n\n\nDISTRIBUCIÓN DE LOS DATOS:\n- Mi Set de datos tiene 1500 observaciones y 27 variables\n- Variables numéricas son: 12\n- Variables categóricas son: 12\nVARIABLE OBJETIVO (Score de TOXICIDAD):\n- Media de toxicidad: 0.2539\n- Desviación estándar: 0.2439\n- La mayoría de tweets tienen baja toxicidad pues son menores a 0.5, la toxicidad media es: 0.2539\nDistribución de `toxicity_score` con mediana, cuartiles y % de valores altos.\nCampos con nulos relevantes (p.ej. `toxicity_score` y `hashtags`).\nConcentración de polaridad y relación preliminar con la toxicidad.",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "Proyecto_final.html#preprocesamiento-y-codificación",
    "href": "Proyecto_final.html#preprocesamiento-y-codificación",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "3 2. Preprocesamiento y codificación",
    "text": "3 2. Preprocesamiento y codificación\n\n\nCode\ndf_procesado = df[['content', 'toxicity_score']].copy()\n\ninitial_rows = len(df_procesado)\ndf_procesado = df_procesado.dropna(subset=['toxicity_score', 'content'])\nfinal_rows = len(df_procesado)\n\n# Función simple de limpieza de texto\ndef clean_text(text):\n    if pd.isna(text):\n        return \"\"\n    \n    text = str(text).lower()\n    # Remover URLs, menciones, hashtags, además números y caracteres especiales\n    text = re.sub(r'http\\S+|www\\S+', '', text)\n    text = re.sub(r'@\\w+', '', text)\n    text = re.sub(r'#\\w+', '', text)\n    text = re.sub(r'\\d+', '', text)\n    text = re.sub(r'[^\\w\\s]', ' ', text)\n    text = ' '.join(text.split())\n    \n    return text\n\n# Aplicar limpieza\ndf_procesado['content_clean'] = df_procesado['content'].apply(clean_text)\n\n# Remover stopwords en español\nspanish_stopwords = set(stopwords.words('spanish'))\n\ndef remove_stopwords(text):\n    words = word_tokenize(text, language='spanish')  # &lt;-- cambio: antes text.split()\n    return ' '.join([word for word in words if word.lower() not in spanish_stopwords and len(word) &gt; 2])\n\n# Crear texto procesado final\ndf_procesado['text_processed'] = df_procesado['content_clean'].apply(remove_stopwords)\nprint(df_procesado)\n\n\n                                                content  toxicity_score  \\\n0     @DanielNoboaOk @DiegoBorjaPC Lávate el hocico ...        0.543256   \n1     @DanielNoboaOk De esa arrastrada no te levanta...        0.426917   \n2     @LuisaGonzalezEc @RC5Oficial Protegiendo a los...        0.555970   \n3             @DanielNoboaOk #NoboaPresidente.  Todo 7!        0.046615   \n4     @slider1908 @LuisaGonzalezEc @DianaAtamaint @c...        0.846027   \n...                                                 ...             ...   \n1494  @dew_tempoperfec @LuisaGonzalezEc @RC5Oficial ...        0.304272   \n1495  @LuisaGonzalezEc De parte de un pensador indep...        0.028739   \n1497  @DanielNoboaOk @DiegoBorjaPC Los que lloran so...        0.285484   \n1498  @LuisaGonzalezEc Será que revela como se puede...        0.010241   \n1499  @DanielNoboaOk Te van a enterrar en las urnas....        0.202656   \n\n                                          content_clean  \\\n0     lávate el hocico presidente de cartón habla la...   \n1     de esa arrastrada no te levantas nunca chao ca...   \n2     protegiendo a los narcotraficantes criminales ...   \n3                                                  todo   \n4                    troll de mierda a callarse la boca   \n...                                                 ...   \n1494  si así mismo esta si es información verídica e...   \n1495  de parte de un pensador independiente cero fan...   \n1497  los que lloran son los padres de los niños de ...   \n1498  será que revela como se puede obtener dinero s...   \n1499     te van a enterrar en las urnas noboa nunca más   \n\n                                         text_processed  \n0     lávate hocico presidente cartón habla verdad c...  \n1                 arrastrada levantas nunca chao cartón  \n2     protegiendo narcotraficantes criminales violad...  \n3                                                        \n4                            troll mierda callarse boca  \n...                                                 ...  \n1494  así mismo información verídica causante divorc...  \n1495  parte pensador independiente cero fanatismo po...  \n1497         lloran padres niños malvinas haces infeliz  \n1498               revela puede obtener dinero trabajar  \n1499                     van enterrar urnas noboa nunca  \n\n[1347 rows x 4 columns]\n\n\n\n\nCode\ntext_col = \"text_processed\"\nnum_cols = [\"authorFollowers\", \"account_age_days\", \"mentions_count\", \"hashtags_count\", \"content_length\", \"sentiment_polarity\"]\ncat_cols = [\"source\", \"has_profile_picture\"]\n\n# Subconjunto para modelado\ndf_model = df[[\"content\", \"toxicity_score\"] + num_cols + cat_cols].copy()\nfor c in num_cols:\n    df_model[c] = pd.to_numeric(df_model[c], errors=\"coerce\")\nfor c in cat_cols:\n    df_model[c] = df_model[c].astype(\"category\")\ndf_model[\"toxicity_score\"] = pd.to_numeric(df_model[\"toxicity_score\"], errors=\"coerce\")\n\n# Añadir la columna de texto procesado alineando por 'content'\ndf_model = df_model.merge(df_procesado[[\"content\", \"text_processed\"]], on=\"content\", how=\"left\")\n\n# Filtrar NAs en texto/target\ndf_model = df_model.dropna(subset=[text_col, \"toxicity_score\"]).reset_index(drop=True)\n\nX = df_model[[text_col] + num_cols + cat_cols]\ny_cont = df_model[\"toxicity_score\"]\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        (\"text\", TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1,2), strip_accents=\"unicode\"), text_col),\n        (\"num\", Pipeline([(\"scaler\", StandardScaler(with_mean=False))]), num_cols),\n        (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), cat_cols),\n    ]\n)\npreprocessor\n\n\nColumnTransformer(transformers=[('text',\n                                 TfidfVectorizer(max_df=0.9, min_df=5,\n                                                 ngram_range=(1, 2),\n                                                 strip_accents='unicode'),\n                                 'text_processed'),\n                                ('num',\n                                 Pipeline(steps=[('scaler',\n                                                  StandardScaler(with_mean=False))]),\n                                 ['authorFollowers', 'account_age_days',\n                                  'mentions_count', 'hashtags_count',\n                                  'content_length', 'sentiment_polarity']),\n                                ('cat', OneHotEncoder(handle_unknown='ignore'),\n                                 ['source', 'has_profile_picture'])])In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ColumnTransformer?Documentation for ColumnTransformeriNot fitted\n        \n            \n                Parameters\n                \n\n\n\n\ntransformers \n[('text', ...), ('num', ...), ...]\n\n\n\nremainder \n'drop'\n\n\n\nsparse_threshold \n0.3\n\n\n\nn_jobs \nNone\n\n\n\ntransformer_weights \nNone\n\n\n\nverbose \nFalse\n\n\n\nverbose_feature_names_out \nTrue\n\n\n\nforce_int_remainder_cols \n'deprecated'\n\n\n\n\n            \n        \n    texttext_processedTfidfVectorizer?Documentation for TfidfVectorizer\n        \n            \n                Parameters\n                \n\n\n\n\ninput \n'content'\n\n\n\nencoding \n'utf-8'\n\n\n\ndecode_error \n'strict'\n\n\n\nstrip_accents \n'unicode'\n\n\n\nlowercase \nTrue\n\n\n\npreprocessor \nNone\n\n\n\ntokenizer \nNone\n\n\n\nanalyzer \n'word'\n\n\n\nstop_words \nNone\n\n\n\ntoken_pattern \n'(?u)\\\\b\\\\w\\\\w+\\\\b'\n\n\n\nngram_range \n(1, ...)\n\n\n\nmax_df \n0.9\n\n\n\nmin_df \n5\n\n\n\nmax_features \nNone\n\n\n\nvocabulary \nNone\n\n\n\nbinary \nFalse\n\n\n\ndtype \n&lt;class 'numpy.float64'&gt;\n\n\n\nnorm \n'l2'\n\n\n\nuse_idf \nTrue\n\n\n\nsmooth_idf \nTrue\n\n\n\nsublinear_tf \nFalse\n\n\n\n\n            \n        \n    num['authorFollowers', 'account_age_days', 'mentions_count', 'hashtags_count', 'content_length', 'sentiment_polarity']StandardScaler?Documentation for StandardScaler\n        \n            \n                Parameters\n                \n\n\n\n\ncopy \nTrue\n\n\n\nwith_mean \nFalse\n\n\n\nwith_std \nTrue\n\n\n\n\n            \n        \n    cat['source', 'has_profile_picture']OneHotEncoder?Documentation for OneHotEncoder\n        \n            \n                Parameters\n                \n\n\n\n\ncategories \n'auto'\n\n\n\ndrop \nNone\n\n\n\nsparse_output \nTrue\n\n\n\ndtype \n&lt;class 'numpy.float64'&gt;\n\n\n\nhandle_unknown \n'ignore'\n\n\n\nmin_frequency \nNone\n\n\n\nmax_categories \nNone\n\n\n\nfeature_name_combiner \n'concat'",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "Proyecto_final.html#clasificación",
    "href": "Proyecto_final.html#clasificación",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "4 3. Clasificación",
    "text": "4 3. Clasificación\n\n\nCode\n# Candidatos de umbral \ncandidate_thresholds = np.array([0.30, 0.40, 0.50, 0.60, 0.70])\n\n# Tabla de balance por umbral elección de target binario\nbalance_rows = []\nfor t in candidate_thresholds:\n    y_tmp = (y_cont &gt;= t).astype(int)\n    pos = int(y_tmp.sum())\n    neg = int((1 - y_tmp).sum())\n    pos_pct = float(y_tmp.mean()) * 100.0\n    balance_rows.append({\"threshold\": t, \"positivos\": pos, \"negativos\": neg, \"pct_positivos\": round(pos_pct, 2)})\nbalance_df = pd.DataFrame(balance_rows).sort_values(\"threshold\")\nprint(\"Balance por umbral :\")\nprint(balance_df.to_string(index=False))\n\n# Criterio simple de selección: tasa objetivo de positivos ≈ 20%\ntarget_pos_rate = 0.20\nbest_threshold = min(candidate_thresholds, key=lambda t: abs(((y_cont &gt;= t).mean()) - target_pos_rate))\nprint(f\"\\nUmbral sugerido por balance de clases (~{int(target_pos_rate*100)}% positivos): {best_threshold:.2f}\")\n\n# -----------------------------------------------------------------\n# Target binario usando el umbral seleccionado\ny_bin = (y_cont &gt;= best_threshold).astype(int)\n\n# Split y entrenamiento\nX_train, X_test, y_train, y_test = train_test_split(X, y_bin, test_size=0.2, random_state=42, stratify=y_bin)\n\npipe_clf = Pipeline([(\"preprocess\", preprocessor),\n                     (\"clf\", RandomForestClassifier(\n                         n_estimators=300,\n                         random_state=42))])\n\npipe_clf.fit(X_train, y_train)\ny_pred = pipe_clf.predict(X_test)\ny_proba = pipe_clf.predict_proba(X_test)[:, 1]\n\nmetrics = {\n    \"threshold_usado\": float(best_threshold),\n    \"accuracy\": accuracy_score(y_test, y_pred),\n    \"precision\": precision_score(y_test, y_pred, zero_division=0),\n    \"recall\": recall_score(y_test, y_pred, zero_division=0),\n    \"f1\": f1_score(y_test, y_pred, zero_division=0),\n    \"roc_auc\": roc_auc_score(y_test, y_proba),\n}\nmetrics\n\n\nBalance por umbral :\n threshold  positivos  negativos  pct_positivos\n       0.3        524        853          38.05\n       0.4        375       1002          27.23\n       0.5        243       1134          17.65\n       0.6        150       1227          10.89\n       0.7         82       1295           5.95\n\nUmbral sugerido por balance de clases (~20% positivos): 0.50\n\n\n{'threshold_usado': 0.5,\n 'accuracy': 0.8405797101449275,\n 'precision': 0.631578947368421,\n 'recall': 0.24489795918367346,\n 'f1': 0.35294117647058826,\n 'roc_auc': 0.7173873954868292}\n\n\n\n\nCode\n# Target binario con umbral 0.5 solo para el split (estratificación estable)\ny_bin_split = (y_cont &gt;= 0.5).astype(int)\nX_train, X_test, y_train, y_test = train_test_split(X, y_bin_split, test_size=0.2, random_state=42, stratify=y_bin_split)\n\nfrom sklearn.ensemble import RandomForestClassifier\n\npipe_clf = Pipeline([(\"preprocess\", preprocessor),\n                     (\"clf\", RandomForestClassifier(\n                         n_estimators=300,\n                         random_state=42))])\n\npipe_clf.fit(X_train, y_train)\n\n# Probabilidades en test\ny_proba = pipe_clf.predict_proba(X_test)[:, 1]\n\n# --- Búsqueda de umbral por F1 ---\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n\nthresholds = np.linspace(0.20, 0.80, 61)  # explora 0.20..0.80\nrows = []\nfor t in thresholds:\n    y_pred_t = (y_proba &gt;= t).astype(int)\n    rows.append({\n        \"threshold\": float(t),\n        \"accuracy\": accuracy_score(y_test, y_pred_t),\n        \"precision\": precision_score(y_test, y_pred_t, zero_division=0),\n        \"recall\": recall_score(y_test, y_pred_t, zero_division=0),\n        \"f1\": f1_score(y_test, y_pred_t, zero_division=0)\n    })\n\nimport pandas as pd\nthr_df = pd.DataFrame(rows)\nbest_row = thr_df.loc[thr_df[\"f1\"].idxmax()]\nbest_threshold = float(best_row[\"threshold\"])\n\n# Métricas con umbral óptimo (F1) vs 0.5\ny_pred_best = (y_proba &gt;= best_threshold).astype(int)\ny_pred_05   = (y_proba &gt;= 0.5).astype(int)\n\nmetrics_best = {\n    \"threshold_usado\": best_threshold,\n    \"accuracy\": accuracy_score(y_test, y_pred_best),\n    \"precision\": precision_score(y_test, y_pred_best, zero_division=0),\n    \"recall\": recall_score(y_test, y_pred_best, zero_division=0),\n    \"f1\": f1_score(y_test, y_pred_best, zero_division=0),\n    \"roc_auc\": roc_auc_score(y_test, y_proba)  # AUC no depende del umbral\n}\n\nmetrics_05 = {\n    \"threshold_usado\": 0.5,\n    \"accuracy\": accuracy_score(y_test, y_pred_05),\n    \"precision\": precision_score(y_test, y_pred_05, zero_division=0),\n    \"recall\": recall_score(y_test, y_pred_05, zero_division=0),\n    \"f1\": f1_score(y_test, y_pred_05, zero_division=0),\n    \"roc_auc\": roc_auc_score(y_test, y_proba)\n}\n\nprint(\"Métricas con umbral óptimo (F1):\", metrics_best)\nprint(\"Métricas con umbral 0.5:\", metrics_05)\n\n\nMétricas con umbral óptimo (F1): {'threshold_usado': 0.22000000000000003, 'accuracy': 0.7789855072463768, 'precision': 0.4, 'recall': 0.4897959183673469, 'f1': 0.44036697247706424, 'roc_auc': 0.7173873954868292}\nMétricas con umbral 0.5: {'threshold_usado': 0.5, 'accuracy': 0.8405797101449275, 'precision': 0.631578947368421, 'recall': 0.24489795918367346, 'f1': 0.35294117647058826, 'roc_auc': 0.7173873954868292}\n\n\n\n\nCode\nConfusionMatrixDisplay.from_predictions(y_test, y_pred)\nplt.title(\"Matriz de confusión - Clasificación\"); plt.tight_layout(); plt.show()",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "Proyecto_final.html#regresión",
    "href": "Proyecto_final.html#regresión",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "5 4. Regresión",
    "text": "5 4. Regresión\n\n\nCode\nX_train_r, X_test_r, y_train_r, y_test_r = train_test_split(X, y_cont, test_size=0.2, random_state=42)\n\npipe_reg = Pipeline([(\"preprocess\", preprocessor), (\"reg\", LinearRegression())])\npipe_reg.fit(X_train_r, y_train_r)\ny_pred_r = pipe_reg.predict(X_test_r)\n\nreg_metrics = {\n    \"MAE\": mean_absolute_error(y_test_r, y_pred_r),\n    \"RMSE\": mean_squared_error(y_test_r, y_pred_r),\n    \"R2\": r2_score(y_test_r, y_pred_r),\n}\nprint(reg_metrics)\n\n\n{'MAE': 0.16806338609617444, 'RMSE': 0.049797216940050744, 'R2': 0.12122430945578111}\n\n\n\n\nCode\nplt.scatter(y_test_r, y_pred_r, alpha=0.6)\nplt.title(\"Real vs. Predicho (Regresión)\"); plt.xlabel(\"Real\"); plt.ylabel(\"Predicho\"); plt.tight_layout(); plt.show()\n\nres = y_test_r - y_pred_r\nplt.scatter(y_pred_r, res, alpha=0.6); plt.axhline(0, linestyle=\"--\")\nplt.title(\"Residuales vs. Predicción\"); plt.xlabel(\"Predicción\"); plt.ylabel(\"Residual\"); plt.tight_layout(); plt.show()",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "Proyecto_final.html#clustering",
    "href": "Proyecto_final.html#clustering",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "6 5. Clustering",
    "text": "6 5. Clustering\n\n\nCode\nnum_cols_cluster = [\"authorFollowers\", \"account_age_days\", \"mentions_count\", \"hashtags_count\", \"content_length\", \"sentiment_polarity\", \"toxicity_score\"]\ndfc = df[num_cols_cluster].apply(pd.to_numeric, errors=\"coerce\").dropna().reset_index(drop=True)\n\nsil_scores = {}\nbest = {\"k\": None, \"score\": -1, \"labels\": None}\n\nfor k in range(2,7):\n    pipe_km = Pipeline([(\"scaler\", StandardScaler()), (\"km\", KMeans(n_clusters=k, n_init=10, random_state=42))])\n    labels = pipe_km.fit_predict(dfc)\n    sil = silhouette_score(dfc, labels)\n    sil_scores[k] = sil\n    if sil &gt; best[\"score\"]:\n        best = {\"k\": k, \"score\": sil, \"labels\": labels, \"model\": pipe_km}\n\nsil_scores, best[\"k\"], best[\"score\"]\n\n\n({2: 0.9985810886175137,\n  3: 0.026805141053596757,\n  4: 0.3169276806296067,\n  5: 0.15365146886270972,\n  6: 0.05436520939889099},\n 2,\n 0.9985810886175137)\n\n\n\n\nCode\ndfvis = dfc.copy()\ndfvis[\"cluster\"] = best[\"labels\"]\nfor cl in sorted(dfvis[\"cluster\"].unique()):\n    part = dfvis[dfvis[\"cluster\"]==cl]\n    plt.scatter(part[\"sentiment_polarity\"], part[\"toxicity_score\"], alpha=0.6, label=f\"Cluster {cl}\")\nplt.legend(); plt.title(f\"Clusters KMeans (k={best['k']})\"); plt.xlabel(\"sentiment_polarity\"); plt.ylabel(\"toxicity_score\"); plt.tight_layout(); plt.show()\n\n# Relación con target binario (0.5)\ny_bin_all = (dfvis[\"toxicity_score\"] &gt;= 0.5).astype(int)\nct = pd.crosstab(dfvis[\"cluster\"], y_bin_all, normalize=\"index\")*100\nct.round(1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntoxicity_score\n0\n1\n\n\ncluster\n\n\n\n\n\n\n0\n81.9\n18.1\n\n\n1\n100.0\n0.0",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "Proyecto_final.html#conclusiones-y-próximos-pasos",
    "href": "Proyecto_final.html#conclusiones-y-próximos-pasos",
    "title": "Análisis ML de Toxicidad en Tweets (Ecuador)",
    "section": "7 6. Conclusiones y próximos pasos",
    "text": "7 6. Conclusiones y próximos pasos\n\nCalidad de datos y nulos: …\n\nJustificación del umbral para clasificación: …\n\nRendimiento de modelos: …\n\nPatrones en clusters vs clases: …\n\nMejoras propuestas: - Probar Ridge o ElasticNet para regresión. - Ajustar umbrales y class_weight en clasificación; búsqueda de hiperparámetros con GridSearchCV. - Expandir features del texto: ngram_range, min_df, limpieza de URLs, usuarios y emojis. - Evaluar reducción de dimensionalidad para clustering/visualización (PCA/TruncatedSVD).",
    "crumbs": [
      "Natural Language Processing (NLP)",
      "Análisis ML de Toxicidad en Tweets (Ecuador)"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Laboratorio 2 - Módulo de aprendizaje de máquina",
    "section": "",
    "text": "Laboratorio 2\nMódulo de aprendizaje de máquina Yachaytech 2025\nRealizado por: Jorge Delgado",
    "crumbs": [
      "Inicio"
    ]
  }
]